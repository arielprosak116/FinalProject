{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# The Revenge of Rocchio's Angels",
   "id": "c6962dbc7032e16e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We will be #1 this time",
   "id": "dd8b17b5e7537cad"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Local Script Dependencies",
   "id": "a330a05fa432fb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T15:46:26.571899700Z",
     "start_time": "2026-01-08T15:46:18.712828700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from engine import SearchEngine\n",
    "from evaluate_map import *\n",
    "from optimizing import Optimize"
   ],
   "id": "6da5113226db22bf",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\PycharmEnvs\\FinalProject\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T15:46:27.183221100Z",
     "start_time": "2026-01-08T15:46:27.012138100Z"
    }
   },
   "cell_type": "code",
   "source": "se = SearchEngine()",
   "id": "4ae9d273b58a4a20",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T15:46:27.255704300Z",
     "start_time": "2026-01-08T15:46:27.198183200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "doc = se.searcher.doc(\"FBIS3-10082\")\n",
    "text = doc.raw()\n",
    "text"
   ],
   "id": "90196c6e1798c67f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<TEXT>\\nLanguage: <F P=105> Spanish </F>\\nArticle Type:BFN\\n\\n[Text] Santa Fe de Bogota, 28 Feb (DPA) -- Today,\\nColombian Prosecutor General Gustavo de Greiff said the U.S.\\nGovernment is not interested in supplying evidence to condemn\\nthe chiefs of the drug trafficking mafia because it does not\\ntrust Colombian justice. In this manner, De Greiff reaffirmed\\nthe difficulties his office has encountered in its attempt to\\ncollect evidence in the United States against the main \"capos\"\\nof the Cali cartel, several of whom have expressed their desire\\nto surrender and collaborate with authorities. \"Colombia is\\nbeing deserted. The United States is not interested in\\ncollaborating with Colombian justice although there are judicial\\nexchange agreements,\" De Greiff pointed out.\\nThe prosecutor general added that U.S. authorities are\\n\"withholding evidence\" to reveal later should the mafiosos be\\ncaptured in their country without taking into account that\\nseveral of them are thinking about surrendering in Colombia. In\\nthe opinion of the director of the Colombian justice system, the\\ngovernment in Washington should change its strategy of\\nwithholding evidence and \"open its doors\" to criminals who wish\\nto surrender and supply valuable information to defeat drug\\ntrafficking.\\nDe Greiff confirmed that his office is still in touch with\\nlawyers who claim to represent Gilberto Rodriguez, charged with\\nbeing the leader of the Cali cartel, as part of a rapprochement\\nprocess, started last year and intensified in the past weeks.\\nTalks between De Greiff and these lawyers have developed so\\nsmoothly that the prosecutor general and the media are not\\nruling out the possibility that Rodriguez, who is known by the\\nalias of \"El Ajedrecista,\" might surrender in mid-March.\\nAccording to official reports, Rodriguez wants to take advantage\\nof the decrees President Cesar Gaviria signed in 1990 offering\\nsubstantial sentence reductions to drug traffickers and\\nterrorists who surrender, confess to at least one crime, and\\neffectively collaborate with the authorities.\\nSpokesmen for the Prosecutor General\\'s Office claim that one\\nof the difficulties facing this process is the lack of evidence\\nto indict the mafiosos because many of the charges made in the\\npast were leveled by the media and cannot be confirmed. Three\\nmen charged with being Cali cartel leaders appeared before the\\nProsecutor General\\'s Office in mid-January but were not held\\nbecause there were no warrants for their arrest.\\n\\n</TEXT>'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T15:46:27.279703Z",
     "start_time": "2026-01-08T15:46:27.266704100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from pyserini.analysis import Analyzer, get_lucene_analyzer\n",
    "# analyzer = get_lucene_analyzer(stemmer='porter', stopwords=False)\n",
    "# se.reader.get_term_counts(\"spanish\",analyzer) #(df,cf)"
   ],
   "id": "cbb07f9239d15fef",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T15:46:27.316707800Z",
     "start_time": "2026-01-08T15:46:27.280704400Z"
    }
   },
   "cell_type": "code",
   "source": "se.set_searcher(approach=\"qld\")",
   "id": "8ab1da462e649059",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T15:46:27.322708600Z",
     "start_time": "2026-01-08T15:46:27.316707800Z"
    }
   },
   "cell_type": "code",
   "source": "topics = load_topics(\"Data/queriesROBUST.txt\")",
   "id": "c070736b11d0f923",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T15:46:42.716725100Z",
     "start_time": "2026-01-08T15:46:27.327213700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# This one creates a file called \"run.txt\" with submitting format, can change file name\n",
    "se.search_all_queries(topics,k=5, m=2, output_file=\"hey.txt\")"
   ],
   "id": "868c2ffeffd32b43",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\PycharmEnvs\\FinalProject\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\idoli\\.cache\\huggingface\\hub\\models--cross-encoder--ms-marco-MiniLM-L-6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "\n",
      "2026-01-08 17:46:29,494 - huggingface_hub.file_download - WARNING - Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# This one creates a file called \"run.txt\" with submitting format, can change file name\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[43mse\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msearch_all_queries\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtopics\u001B[49m\u001B[43m,\u001B[49m\u001B[43mk\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mm\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_file\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mhey.txt\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\PycharmProjects\\FinalProject\\engine.py:106\u001B[0m, in \u001B[0;36mSearchEngine.search_all_queries\u001B[1;34m(self, topics, k, run_tag, output_file, m)\u001B[0m\n\u001B[0;32m    103\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[0;32m    105\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m qid, query \u001B[38;5;129;01min\u001B[39;00m topics\u001B[38;5;241m.\u001B[39mitems():\n\u001B[1;32m--> 106\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msearch_and_write_trec_run\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquery\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mk\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mqid\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_tag\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_file\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mm\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mm\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\PycharmProjects\\FinalProject\\engine.py:83\u001B[0m, in \u001B[0;36mSearchEngine.search_and_write_trec_run\u001B[1;34m(self, query, k, topic_id, run_tag, output_file, m)\u001B[0m\n\u001B[0;32m     82\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21msearch_and_write_trec_run\u001B[39m(\u001B[38;5;28mself\u001B[39m, query, k, topic_id, run_tag, output_file, m\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m):\n\u001B[1;32m---> 83\u001B[0m     hits \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mretrieve_rerank\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquery\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mk\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mm\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     84\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(output_file, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124ma\u001B[39m\u001B[38;5;124m\"\u001B[39m, encoding\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[0;32m     85\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m rank, hit \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(hits, start\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m):\n",
      "File \u001B[1;32mD:\\PycharmProjects\\FinalProject\\engine.py:78\u001B[0m, in \u001B[0;36mSearchEngine.retrieve_rerank\u001B[1;34m(self, query, k, m)\u001B[0m\n\u001B[0;32m     76\u001B[0m top_m \u001B[38;5;241m=\u001B[39m hits[:m]\n\u001B[0;32m     77\u001B[0m passages_top_m \u001B[38;5;241m=\u001B[39m split_passages(top_m)\n\u001B[1;32m---> 78\u001B[0m docs_reranked \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrerank\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquery\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpassages_top_m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     79\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m docs_reranked\n",
      "File \u001B[1;32mD:\\PycharmProjects\\FinalProject\\engine.py:61\u001B[0m, in \u001B[0;36mSearchEngine.rerank\u001B[1;34m(self, query, retrieval_candidates, max_weight)\u001B[0m\n\u001B[0;32m     59\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_collated_doc_score\u001B[39m(scores, max_weight\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.8\u001B[39m):\n\u001B[0;32m     60\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mmax\u001B[39m(scores)\u001B[38;5;241m*\u001B[39mmax_weight \u001B[38;5;241m+\u001B[39m (\u001B[38;5;241m1\u001B[39m\u001B[38;5;241m-\u001B[39mmax_weight)\u001B[38;5;241m*\u001B[39m(\u001B[38;5;28msum\u001B[39m(scores)\u001B[38;5;241m-\u001B[39m\u001B[38;5;28mmax\u001B[39m(scores))\u001B[38;5;241m/\u001B[39m(\u001B[38;5;28mlen\u001B[39m(scores)\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m---> 61\u001B[0m reranker \u001B[38;5;241m=\u001B[39m \u001B[43mCrossEncoder\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcross-encoder/ms-marco-MiniLM-L-6-v2\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcuda\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;66;03m#TODO should be initialized at the start\u001B[39;00m\n\u001B[0;32m     62\u001B[0m pairs \u001B[38;5;241m=\u001B[39m [[query, _remove_whitespaces(doc\u001B[38;5;241m.\u001B[39mpage_content)] \u001B[38;5;28;01mfor\u001B[39;00m doc \u001B[38;5;129;01min\u001B[39;00m retrieval_candidates]\n\u001B[0;32m     63\u001B[0m cross_scores \u001B[38;5;241m=\u001B[39m reranker\u001B[38;5;241m.\u001B[39mpredict(pairs)\n",
      "File \u001B[1;32mD:\\PycharmEnvs\\FinalProject\\lib\\site-packages\\sentence_transformers\\cross_encoder\\util.py:39\u001B[0m, in \u001B[0;36mcross_encoder_init_args_decorator.<locals>.wrapper\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m     36\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     37\u001B[0m         kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mconfig_kwargs\u001B[39m\u001B[38;5;124m\"\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mclassifier_dropout\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m classifier_dropout\n\u001B[1;32m---> 39\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mD:\\PycharmEnvs\\FinalProject\\lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:229\u001B[0m, in \u001B[0;36mCrossEncoder.__init__\u001B[1;34m(self, model_name_or_path, num_labels, max_length, activation_fn, device, cache_folder, trust_remote_code, revision, local_files_only, token, model_kwargs, tokenizer_kwargs, config_kwargs, model_card_data, backend)\u001B[0m\n\u001B[0;32m    227\u001B[0m     device \u001B[38;5;241m=\u001B[39m get_device_name()\n\u001B[0;32m    228\u001B[0m     logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUse pytorch device: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdevice\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 229\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    231\u001B[0m \u001B[38;5;66;03m# Pass the model to the model card data for later use in generating a model card upon saving this model\u001B[39;00m\n\u001B[0;32m    232\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel_card_data\u001B[38;5;241m.\u001B[39mregister_model(\u001B[38;5;28mself\u001B[39m)\n",
      "File \u001B[1;32mD:\\PycharmEnvs\\FinalProject\\lib\\site-packages\\torch\\nn\\modules\\module.py:1371\u001B[0m, in \u001B[0;36mModule.to\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1368\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1369\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m\n\u001B[1;32m-> 1371\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconvert\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\PycharmEnvs\\FinalProject\\lib\\site-packages\\torch\\nn\\modules\\module.py:930\u001B[0m, in \u001B[0;36mModule._apply\u001B[1;34m(self, fn, recurse)\u001B[0m\n\u001B[0;32m    928\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m recurse:\n\u001B[0;32m    929\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[1;32m--> 930\u001B[0m         \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    932\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mbool\u001B[39m:\n\u001B[0;32m    933\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[0;32m    934\u001B[0m         \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[0;32m    935\u001B[0m         \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    940\u001B[0m         \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[0;32m    941\u001B[0m         \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "File \u001B[1;32mD:\\PycharmEnvs\\FinalProject\\lib\\site-packages\\torch\\nn\\modules\\module.py:930\u001B[0m, in \u001B[0;36mModule._apply\u001B[1;34m(self, fn, recurse)\u001B[0m\n\u001B[0;32m    928\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m recurse:\n\u001B[0;32m    929\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[1;32m--> 930\u001B[0m         \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    932\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mbool\u001B[39m:\n\u001B[0;32m    933\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[0;32m    934\u001B[0m         \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[0;32m    935\u001B[0m         \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    940\u001B[0m         \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[0;32m    941\u001B[0m         \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "    \u001B[1;31m[... skipping similar frames: Module._apply at line 930 (1 times)]\u001B[0m\n",
      "File \u001B[1;32mD:\\PycharmEnvs\\FinalProject\\lib\\site-packages\\torch\\nn\\modules\\module.py:930\u001B[0m, in \u001B[0;36mModule._apply\u001B[1;34m(self, fn, recurse)\u001B[0m\n\u001B[0;32m    928\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m recurse:\n\u001B[0;32m    929\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[1;32m--> 930\u001B[0m         \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    932\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mbool\u001B[39m:\n\u001B[0;32m    933\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[0;32m    934\u001B[0m         \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[0;32m    935\u001B[0m         \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    940\u001B[0m         \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[0;32m    941\u001B[0m         \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "File \u001B[1;32mD:\\PycharmEnvs\\FinalProject\\lib\\site-packages\\torch\\nn\\modules\\module.py:957\u001B[0m, in \u001B[0;36mModule._apply\u001B[1;34m(self, fn, recurse)\u001B[0m\n\u001B[0;32m    953\u001B[0m \u001B[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001B[39;00m\n\u001B[0;32m    954\u001B[0m \u001B[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001B[39;00m\n\u001B[0;32m    955\u001B[0m \u001B[38;5;66;03m# `with torch.no_grad():`\u001B[39;00m\n\u001B[0;32m    956\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[1;32m--> 957\u001B[0m     param_applied \u001B[38;5;241m=\u001B[39m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparam\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    958\u001B[0m p_should_use_set_data \u001B[38;5;241m=\u001B[39m compute_should_use_set_data(param, param_applied)\n\u001B[0;32m    960\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_subclasses\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfake_tensor\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m FakeTensor\n",
      "File \u001B[1;32mD:\\PycharmEnvs\\FinalProject\\lib\\site-packages\\torch\\nn\\modules\\module.py:1357\u001B[0m, in \u001B[0;36mModule.to.<locals>.convert\u001B[1;34m(t)\u001B[0m\n\u001B[0;32m   1350\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m convert_to_format \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m t\u001B[38;5;241m.\u001B[39mdim() \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;241m4\u001B[39m, \u001B[38;5;241m5\u001B[39m):\n\u001B[0;32m   1351\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m t\u001B[38;5;241m.\u001B[39mto(\n\u001B[0;32m   1352\u001B[0m             device,\n\u001B[0;32m   1353\u001B[0m             dtype \u001B[38;5;28;01mif\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_floating_point() \u001B[38;5;129;01mor\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_complex() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   1354\u001B[0m             non_blocking,\n\u001B[0;32m   1355\u001B[0m             memory_format\u001B[38;5;241m=\u001B[39mconvert_to_format,\n\u001B[0;32m   1356\u001B[0m         )\n\u001B[1;32m-> 1357\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1358\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1359\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mis_floating_point\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mis_complex\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m   1360\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnon_blocking\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1361\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1362\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m   1363\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mstr\u001B[39m(e) \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot copy out of meta tensor; no data!\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[1;32mD:\\PycharmEnvs\\FinalProject\\lib\\site-packages\\torch\\cuda\\__init__.py:403\u001B[0m, in \u001B[0;36m_lazy_init\u001B[1;34m()\u001B[0m\n\u001B[0;32m    398\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[0;32m    399\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    400\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmultiprocessing, you must use the \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mspawn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m start method\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    401\u001B[0m     )\n\u001B[0;32m    402\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(torch\u001B[38;5;241m.\u001B[39m_C, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_cuda_getDeviceCount\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m--> 403\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTorch not compiled with CUDA enabled\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    404\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _cudart \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    405\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\n\u001B[0;32m    406\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    407\u001B[0m     )\n",
      "\u001B[1;31mAssertionError\u001B[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T14:01:55.759283900Z",
     "start_time": "2026-01-08T14:01:55.170506300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "qrels = load_qrels(\"Data/qrels_50_Queries\")   # or \"qrel301.txt\"\n",
    "run   = load_run(\"Results/run.txt\")\n",
    "\n",
    "map_score, ap_by_q = mean_average_precision(qrels, run)\n",
    "map_score"
   ],
   "id": "37c144d52d85f00d",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_qrels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m qrels \u001B[38;5;241m=\u001B[39m \u001B[43mload_qrels\u001B[49m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mData/qrels_50_Queries\u001B[39m\u001B[38;5;124m\"\u001B[39m)   \u001B[38;5;66;03m# or \"qrel301.txt\"\u001B[39;00m\n\u001B[0;32m      2\u001B[0m run   \u001B[38;5;241m=\u001B[39m load_run(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mResults/run.txt\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      4\u001B[0m map_score, ap_by_q \u001B[38;5;241m=\u001B[39m mean_average_precision(qrels, run)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'load_qrels' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T22:41:16.531159900Z",
     "start_time": "2026-01-07T22:41:16.501649800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "stats = se.reader.stats()\n",
    "print(f\"average terms per doc: {stats['total_terms']/stats['documents']}\")"
   ],
   "id": "2103da6a327cd83e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average terms per doc: 330.5510520235593\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T14:00:21.792944700Z",
     "start_time": "2026-01-08T14:00:21.158906100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "doc = se.searcher.doc(\"FT921-3160\")\n",
    "text = doc.raw()\n",
    "text"
   ],
   "id": "730d85da0d99e8fb",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'se' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m doc \u001B[38;5;241m=\u001B[39m \u001B[43mse\u001B[49m\u001B[38;5;241m.\u001B[39msearcher\u001B[38;5;241m.\u001B[39mdoc(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFT921-3160\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      2\u001B[0m text \u001B[38;5;241m=\u001B[39m doc\u001B[38;5;241m.\u001B[39mraw()\n\u001B[0;32m      3\u001B[0m text\n",
      "\u001B[1;31mNameError\u001B[0m: name 'se' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-06T13:17:11.530551200Z",
     "start_time": "2026-01-06T13:17:11.008317100Z"
    }
   },
   "cell_type": "code",
   "source": "map = get_map_by_paths(\"Data/qrels_50_Queries\", \"Results/run.txt\")",
   "id": "af0ff13b1d2f05ef",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-06T13:18:42.171439700Z",
     "start_time": "2026-01-06T13:18:41.542783300Z"
    }
   },
   "cell_type": "code",
   "source": "map",
   "id": "76b28e10772bc130",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21283191880598026"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-06T16:38:38.669022400Z",
     "start_time": "2026-01-06T16:28:28.341446600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "opti = Optimize()\n",
    "# fb_terms_values = [5, 6, 8, 10, 15, 20]\n",
    "# fb_docs_values = [5, 7, 10, 15]\n",
    "# og_query_weight_values = [0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "mus = [200,300,400,500,600,700,800,900,1000,1100,1200]\n",
    "\n",
    "opti.optimize_qld(topics, [20], [5], [0.6], mus, k=1000)"
   ],
   "id": "c188f7e310540d19",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fb_terms=20, fb_docs=5, w=0.6, mu=200 -> MAP=0.259288\n",
      "fb_terms=20, fb_docs=5, w=0.6, mu=300 -> MAP=0.264891\n",
      "fb_terms=20, fb_docs=5, w=0.6, mu=400 -> MAP=0.264188\n",
      "fb_terms=20, fb_docs=5, w=0.6, mu=500 -> MAP=0.263658\n",
      "fb_terms=20, fb_docs=5, w=0.6, mu=600 -> MAP=0.262625\n",
      "fb_terms=20, fb_docs=5, w=0.6, mu=700 -> MAP=0.259600\n",
      "fb_terms=20, fb_docs=5, w=0.6, mu=800 -> MAP=0.256631\n",
      "fb_terms=20, fb_docs=5, w=0.6, mu=900 -> MAP=0.254628\n",
      "fb_terms=20, fb_docs=5, w=0.6, mu=1000 -> MAP=0.253824\n",
      "fb_terms=20, fb_docs=5, w=0.6, mu=1100 -> MAP=0.251106\n",
      "fb_terms=20, fb_docs=5, w=0.6, mu=1200 -> MAP=0.249275\n",
      "\n",
      "BEST:\n",
      "fb_terms=20, fb_docs=5, w=0.6, mu=300 -> MAP=0.264891\n"
     ]
    }
   ],
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
