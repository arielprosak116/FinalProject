{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# The Revenge of Rocchio's Angels",
   "id": "231e1bd7b2c528ce"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We will be #1 this time",
   "id": "e52cea1cfa4f2dcf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Local Script Dependencies",
   "id": "d1d0a2ca9a03cf42"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from engine import SearchEngine\n",
    "from evaluate_map import *\n",
    "from optimizing import Optimize\n",
    "import shutil\n",
    "import os"
   ],
   "id": "c825986b6b636d6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Full (Current) Pipeline",
   "id": "9a35960143bab9e1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "topics = load_topics(\"Data/queriesROBUST.txt\")\n",
    "topics_expanded = load_topics(\"Data/chatExpandedQueries.txt\")\n",
    "topics_thes = load_topics(\"Data/chatQueries.txt\")\n",
    "qrels = load_qrels(\"Data/qrels_50_Queries\")"
   ],
   "id": "a173077a3f23ac69"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def subset_topics(topics, qids_list):\n",
    "    topics_subset = {\n",
    "        k: v\n",
    "        for k, v in topics.items()\n",
    "        if int(k) in qids_list\n",
    "    }\n",
    "    return topics_subset\n",
    "\n",
    "train_qids = list(range(301,351))\n",
    "HARD_QUERIES =[309, 308, 338, 344, 348, 320, 328, 334, 303, 339] # From EDA, queries with low amounts of relevant documents.\n",
    "topics_subset = subset_topics(topics, train_qids)\n",
    "topics_expanded_subset = subset_topics(topics_expanded, train_qids)\n",
    "topics_thes_subset = subset_topics(topics_thes, train_qids)\n",
    "\n",
    "topics_hard = subset_topics(topics, HARD_QUERIES)\n",
    "topics_expanded_hard = subset_topics(topics_expanded, HARD_QUERIES)\n",
    "topics_thes_hard = subset_topics(topics_thes, HARD_QUERIES)\n"
   ],
   "id": "5bf748809b6adc46"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def compare_rerankers(topics_lists, qrels, rerankers, fusion_weights, query_fusion_weights, rrf_k_queries, rrf_k_reranker):\n",
    "    os.makedirs(f\"Results\",exist_ok=True)\n",
    "    shutil.rmtree(\"Results\")\n",
    "    os.makedirs(f\"Results\",exist_ok=True)\n",
    "    for reranker in rerankers:\n",
    "        print(f\"Starting retrieval with reranker {reranker}\")\n",
    "        se = SearchEngine()\n",
    "        se.set_searcher(approach=\"bm25\",fb_terms=20, fb_docs=5, original_query_weight=0.6, mu=340, reranker=reranker)\n",
    "        se.search_all_queries(topics_lists, k=1000, m=400, output_file=f\"run_{reranker}\", rerank_fusion_weights=fusion_weights, llm_query_fusion_weights=query_fusion_weights, rrf_k_queries=rrf_k_queries, rrf_k_reranker=rrf_k_reranker)\n",
    "        for fusion_weight in fusion_weights:\n",
    "            run = load_run(f\"Results/run_{reranker}_rrf_{fusion_weight}.txt\")\n",
    "            map_score, ap_by_q = mean_average_precision(qrels, run)\n",
    "            print(f\"MAP for reranker {reranker} with rrf {fusion_weight}: {map_score}\")"
   ],
   "id": "384688bb94f13559"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def fuse_rerankers(reranker_type, pre_fusion_weights, post_fusion_weights, topics, rrf_k=60):\n",
    "    \"\"\"\n",
    "    Performs rrf fusion on all the variants of one reranker.\n",
    "    \"\"\"\n",
    "    from processing import Hit\n",
    "    from engine import weighted_rrf_fuse\n",
    "    all_runs = []\n",
    "    for fusion_weight in pre_fusion_weights:\n",
    "        base = load_run(f\"tofuse/run_{reranker_type}_rrf_{fusion_weight}.txt\")\n",
    "        run_hit_format = {}\n",
    "        for qid in base.keys():\n",
    "            run_hit_format[qid]=[Hit(docid=docid, score=0) for docid in base[qid]]\n",
    "        all_runs.append(run_hit_format)\n",
    "\n",
    "    fused = {}\n",
    "    for qid in topics.keys():\n",
    "        fused[qid] = weighted_rrf_fuse([run[qid] for run in all_runs], weights=post_fusion_weights, rrf_k=rrf_k)\n",
    "        with open(f\"Results/fused_fused_rrf_{rrf_k}.txt\", \"a\", encoding=\"utf-8\") as f:\n",
    "            for rank, hit in enumerate(fused[qid], start=1):\n",
    "                f.write(\n",
    "                    f\"{qid} Q0 {hit.docid} {rank} {hit.score:.6f} run42\\n\"\n",
    "                )\n",
    "\n",
    "    run = load_run(f\"Results/fused_fused_rrf_{rrf_k}.txt\")\n",
    "    map_score, ap_by_q = mean_average_precision(qrels, run)\n",
    "    print(f\"MAP for fusion of rerankers of type {reranker_type} with rrf {rrf_k}: {map_score}\")\n"
   ],
   "id": "8b12627e9aa090a2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "fuse_rerankers('CE', [0, 0.2, 0.5, 0.7, 1], [0.0,0.25,0.25,0.25,0.25], topics_subset, rrf_k=10)",
   "id": "e0c903785f80df"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# NOTE - fusion_weight = 0 means we take only the reranker, 1 means we take none of the reranker's inputs and it should be identical to pure lexical\n",
    "# For pure lexical only, specify rerankers = [None]\n",
    "# BEST RESULT IS rrf_k = 9\n",
    "compare_rerankers([topics_subset, topics_expanded_subset, topics_thes], qrels, rerankers= [\"CE\"], fusion_weights=[0, 0.2, 0.5, 0.7, 1], query_fusion_weights=[0.8, 0.2, 0.0], rrf_k_queries=9, rrf_k_reranker=60)\n",
    "\n",
    "# for i in range(3,40,2):\n",
    "#     compare_rerankers([topics_subset, topics_expanded_subset, topics_thes], qrels, [None], fusion_weights=[0, 0.2, 0.5, 0.7, 1], rrf_k=i, should_rerank_embedded=True)\n",
    "\n",
    "#\n",
    "# run = load_run(f\"Results/run_CE_rrf_ariel_hits.txt\")\n",
    "# map_score, ap_by_q = mean_average_precision(qrels, run)\n",
    "# print(f\"MAP is: {map_score}\")\n"
   ],
   "id": "53956a1a50a30c4d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Get LLM datasets and optimize",
   "id": "5c0e0e7d41490218"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from processing import create_llm_generated_queries\n",
    "create_llm_generated_queries(\"Data/LLM_outputs.txt\")"
   ],
   "id": "91eb0cca37b1e1fb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def compare_llm_weights(queries_paths, qrels, rerankers, fusion_weights):\n",
    "    topics_per_path = [load_topics(path) for path in queries_paths]\n",
    "    shutil.rmtree(\"Results\")\n",
    "    os.makedirs(f\"Results\",exist_ok=True)\n",
    "    for reranker in rerankers:\n",
    "        print(f\"Starting retrieval with reranker {reranker}\")\n",
    "        se = SearchEngine()\n",
    "        se.set_searcher(approach=\"bm25\",fb_terms=20, fb_docs=5, original_query_weight=0.6, mu=300, reranker=\"CE\")\n",
    "        se.search_all_queries(topics, k=1000, m=100, output_file=f\"run_{reranker}\", rerank_fusion_weights=0.2)\n",
    "        for fusion_weight in fusion_weights:\n",
    "            run = load_run(f\"Results/run_{reranker}_rrf_{fusion_weight}.txt\")\n",
    "            map_score, ap_by_q = mean_average_precision(qrels, run)\n",
    "            print(f\"MAP for reranker {reranker} with rrf {fusion_weight}: {map_score}\")\n",
    "            if reranker is None:\n",
    "                break\n"
   ],
   "id": "3db1d76bce4e01ca"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Save intermediate results",
   "id": "8eb2c841859830e6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from processing import write_topk_jsonl_query, iter_query_hits\n",
    "def save_inter_results(topics_subset):\n",
    "    se = SearchEngine()\n",
    "    se.set_searcher(approach=\"bm25\",fb_terms=20, fb_docs=5, original_query_weight=0.6, mu=300, reranker=None)\n",
    "    for qid, query in topics_subset.items():\n",
    "        hits = se.get_top_k(query, 1000, clean=True)\n",
    "        write_topk_jsonl_query(hits, \"inter_bm25_rm3.jsonl\", qid)"
   ],
   "id": "99cc7650af1b1fc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "save_inter_results(topics_subset)",
   "id": "aa83bab3b5cca42b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def check_jsonl_results(jsonl_path):\n",
    "    for qid, hits in iter_query_hits(jsonl_path):\n",
    "        with open(f\"Results/jsonl_res.txt\", \"a\", encoding=\"utf-8\") as f:\n",
    "            for rank, hit in enumerate(hits, start=1):\n",
    "                f.write(\n",
    "                    f\"{qid} Q0 {hit.docid} {rank} {hit.score:.6f} {1}\\n\"\n",
    "                )\n",
    "    run = load_run(f\"Results/jsonl_res.txt\")\n",
    "    map_score, ap_by_q = mean_average_precision(qrels, run)\n",
    "    print(f\"MAP is: {map_score}\")"
   ],
   "id": "378e11cc51fcc72d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "check_jsonl_results(\"inter_bm25_rm3.jsonl\")",
   "id": "88a1356ba0b40d5e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": " Extract Train Set Results",
   "id": "174aebcaaa2b0a09"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "HARD_QUERIES =[309, 308, 338, 344, 348, 320, 328, 334, 303, 339] # From EDA",
   "id": "ca1f2f7e5bed7978"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "all_hits = {}\n",
    "hard_hits = {}\n",
    "for i, (qid, topic) in enumerate(topics.items()):\n",
    "    results = se.get_top_k(topic, k=1000, clean=True)\n",
    "    all_hits[f\"{qid}_{topic}\"] = results\n",
    "    if int(qid) in HARD_QUERIES:\n",
    "        hard_hits[f\"{qid}_{topic}\"] = results\n",
    "    if i==49:\n",
    "        print(qid)\n",
    "        break\n",
    "\n",
    "import pickle\n",
    "with open(\"pkls/top1000_rm3_train.pkl\", \"wb\") as f:\n",
    "    pickle.dump(all_hits, f)\n",
    "with open(\"pkls/top1000_rm3_train_hard.pkl\", \"wb\") as f:\n",
    "    pickle.dump(hard_hits, f)"
   ],
   "id": "b8e154a1270b323b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "res",
   "id": "1454236e1223ff22"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# from pyserini.analysis import Analyzer, get_lucene_analyzer\n",
    "# analyzer = get_lucene_analyzer(stemmer='porter', stopwords=False)\n",
    "# se.reader.get_term_counts(\"spanish\",analyzer) #(df,cf)"
   ],
   "id": "4fdaf82062fdf5ff"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# This one creates a file called \"run.txt\" with submitting format, can change file name\n",
    "se.search_all_queries(topics, k=5, m=2, output_file=\"Results/hey.txt\")"
   ],
   "id": "d88df81520a163ec"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "qrels = load_qrels(\"Data/qrels_50_Queries\")   # or \"qrel301.txt\"\n",
    "run   = load_run(\"Results/run.txt\")\n",
    "\n",
    "map_score, ap_by_q = mean_average_precision(qrels, run)\n",
    "map_score"
   ],
   "id": "fa37c828f0d02d2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "stats = se.reader.stats()\n",
    "print(f\"average terms per doc: {stats['total_terms']/stats['documents']}\")"
   ],
   "id": "ad0a1559f12000c7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "doc = se.searcher.doc(\"FT921-3160\")\n",
    "text = doc.raw()\n",
    "text"
   ],
   "id": "ca35d6c9b600edeb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "map = get_map_by_paths(\"Data/qrels_50_Queries\", \"Results/run.txt\")",
   "id": "21e8bab3c2a11942"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "opti = Optimize()\n",
    "# fb_terms_values = [5, 6, 8, 10, 15, 20]\n",
    "# fb_docs_values = [5, 7, 10, 15]\n",
    "# og_query_weight_values = [0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "mus = [200,300,400,500,600,700,800,900,1000,1100,1200]\n",
    "\n",
    "opti.optimize_qld(topics, [20], [5], [0.6], mus, k=1000)"
   ],
   "id": "b3c31bca8b5b012b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
