{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# The Revenge of Rocchio's Angels",
   "id": "231e1bd7b2c528ce"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We will be #1 this time",
   "id": "e52cea1cfa4f2dcf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Local Script Dependencies",
   "id": "d1d0a2ca9a03cf42"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T19:31:28.208767600Z",
     "start_time": "2026-01-21T19:31:19.633980900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from engine import SearchEngine\n",
    "from evaluate_map import *\n",
    "from optimizing import Optimize\n",
    "import shutil\n",
    "import os"
   ],
   "id": "c825986b6b636d6",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\PycharmEnvs\\FinalProject\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Full (Current) Pipeline",
   "id": "9a35960143bab9e1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T19:31:28.256882900Z",
     "start_time": "2026-01-21T19:31:28.209766900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "topics = load_topics(\"Data/queriesROBUST.txt\")\n",
    "topics_expanded = load_topics(\"Data/chatExpandedQueries.txt\")\n",
    "topics_thes = load_topics(\"Data/chatQueries.txt\")\n",
    "qrels = load_qrels(\"Data/qrels_50_Queries\")"
   ],
   "id": "a173077a3f23ac69",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T19:31:28.272886200Z",
     "start_time": "2026-01-21T19:31:28.257881800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def subset_topics(topics, qids_list):\n",
    "    topics_subset = {\n",
    "        k: v\n",
    "        for k, v in topics.items()\n",
    "        if int(k) in qids_list\n",
    "    }\n",
    "    return topics_subset\n",
    "\n",
    "train_qids = list(range(301,351))\n",
    "HARD_QUERIES =[309, 308, 338, 344, 348, 320, 328, 334, 303, 339] # From EDA, queries with low amounts of relevant documents.\n",
    "topics_subset = subset_topics(topics, train_qids)\n",
    "topics_expanded_subset = subset_topics(topics_expanded, train_qids)\n",
    "topics_thes_subset = subset_topics(topics_thes, train_qids)\n",
    "\n",
    "topics_hard = subset_topics(topics, HARD_QUERIES)\n",
    "topics_expanded_hard = subset_topics(topics_expanded, HARD_QUERIES)\n",
    "topics_thes_hard = subset_topics(topics_thes, HARD_QUERIES)\n"
   ],
   "id": "5bf748809b6adc46",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T19:31:31.638488300Z",
     "start_time": "2026-01-21T19:31:28.273885Z"
    }
   },
   "cell_type": "code",
   "source": [
    "optimizer = Optimize()\n",
    "result_dfs = optimizer.tune_bm25_rm3_rrf(\n",
    "    qrels=qrels,\n",
    "    topics_lists=[topics_subset, topics_expanded_subset, topics_thes],\n",
    "    query_fusion_weights_lists=[[0.8,0.2,0.0], [0.7, 0.2, 0.1]],\n",
    "    fb_terms_values=[10, 20, 40],\n",
    "    fb_docs_values=[5, 10, 20, 50],\n",
    "    bm25_k1_values=[0.5, 1.8],\n",
    "    bm25_b_values=[0.36, 0.5, 0.7],\n",
    "    rrf_k_values=[10, 60],\n",
    "    eval_recall_k=400,\n",
    "    out_dir=\"Results/tuning\", # Results/\n",
    ")"
   ],
   "id": "4415bf3b2e95c477",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Searching topics:   0%|          | 0/50 [00:02<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Weights must sum to 1.0",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m Optimize()\n\u001B[1;32m----> 2\u001B[0m result_dfs \u001B[38;5;241m=\u001B[39m \u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtune_bm25_rm3_rrf\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43mqrels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mqrels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtopics_lists\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mtopics_subset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtopics_expanded_subset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtopics_thes\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43mquery_fusion_weights_lists\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0.7\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfb_terms_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m20\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m40\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfb_docs_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m20\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m50\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      8\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbm25_k1_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0.5\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1.8\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      9\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbm25_b_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0.36\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.5\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.7\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     10\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrrf_k_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m60\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     11\u001B[0m \u001B[43m    \u001B[49m\u001B[43meval_recall_k\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m400\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     12\u001B[0m \u001B[43m    \u001B[49m\u001B[43mout_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mResults/tuning\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;66;43;03m# Results/\u001B[39;49;00m\n\u001B[0;32m     13\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\PycharmProjects\\FinalProject\\optimizing.py:119\u001B[0m, in \u001B[0;36mOptimize.tune_bm25_rm3_rrf\u001B[1;34m(self, qrels, topics_lists, query_fusion_weights_lists, fb_terms_values, fb_docs_values, bm25_k1_values, bm25_b_values, rrf_k_values, eval_recall_k, out_dir, run_tag)\u001B[0m\n\u001B[0;32m    117\u001B[0m run_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mrun_tag\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_fbT\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfb_terms\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_fbD\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfb_docs\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_k1\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mk1\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_b\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mb\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_rrf\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mrrf_k\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    118\u001B[0m run_path \u001B[38;5;241m=\u001B[39m out_dir \u001B[38;5;241m/\u001B[39m run_name\n\u001B[1;32m--> 119\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mse\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msearch_all_queries\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    120\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtopics_lists\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtopics_lists\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    121\u001B[0m \u001B[43m    \u001B[49m\u001B[43mllm_query_fusion_weights\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mquery_fusion_weights\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    122\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrrf_k_queries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrrf_k\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    123\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mout_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    124\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_file\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mrun_name\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    125\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    127\u001B[0m run \u001B[38;5;241m=\u001B[39m load_run(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mstr\u001B[39m(run_path)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_rrf_rerank_1.txt\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    129\u001B[0m \u001B[38;5;66;03m# Evaluate (simple set: MAP + Recall at chosen k; plus a fixed early precision)\u001B[39;00m\n",
      "File \u001B[1;32mD:\\PycharmProjects\\FinalProject\\engine.py:248\u001B[0m, in \u001B[0;36mSearchEngine.search_all_queries\u001B[1;34m(self, topics_lists, k, run_tag, output_file, output_dir, m, llm_query_fusion_weights, rerank_fusion_weights, rrf_k_queries, rrf_k_reranker)\u001B[0m\n\u001B[0;32m    246\u001B[0m     llm_query_fusion_weights \u001B[38;5;241m=\u001B[39m [\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m+\u001B[39m[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m*\u001B[39m(\u001B[38;5;28mlen\u001B[39m(topics_lists) \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m    247\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m qid, query \u001B[38;5;129;01min\u001B[39;00m tqdm(topics_lists[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mitems(), desc\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSearching topics\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m--> 248\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msearch_and_write_trec_run\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquery\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mk\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mqid\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_tag\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43moutput_dir\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_file\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mm\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    249\u001B[0m \u001B[43m                                   \u001B[49m\u001B[43mfusion_weights\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrerank_fusion_weights\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mquery_weights\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mllm_query_fusion_weights\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    250\u001B[0m \u001B[43m                                   \u001B[49m\u001B[43mtopics_lists\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtopics_lists\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrrf_k_queries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrrf_k_queries\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrrf_k_reranker\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrrf_k_reranker\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\PycharmProjects\\FinalProject\\engine.py:214\u001B[0m, in \u001B[0;36mSearchEngine.search_and_write_trec_run\u001B[1;34m(self, query, k, topic_id, run_tag, output_file, fusion_weights, query_weights, topics_lists, m, rrf_k_queries, rrf_k_reranker)\u001B[0m\n\u001B[0;32m    212\u001B[0m     fusion_weights \u001B[38;5;241m=\u001B[39m [\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m    213\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m k \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minitial retrieval k must be bigger-equal than fine reranker m\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m--> 214\u001B[0m hits \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmulti_query_fuse\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtopic_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtopics_lists\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mquery_weights\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mk\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mk\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrrf_k\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrrf_k_queries\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Hits are score-sorted by default\u001B[39;00m\n\u001B[0;32m    215\u001B[0m hits_per_fusion_weight \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mretrieve_rerank(query, hits, m, fusion_weights, rrf_k\u001B[38;5;241m=\u001B[39mrrf_k_reranker)\n\u001B[0;32m    216\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, hits \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(hits_per_fusion_weight):\n",
      "File \u001B[1;32mD:\\PycharmProjects\\FinalProject\\engine.py:188\u001B[0m, in \u001B[0;36mSearchEngine.multi_query_fuse\u001B[1;34m(self, qid, topics_list, llm_query_fusion_weights, k, rrf_k)\u001B[0m\n\u001B[0;32m    186\u001B[0m         query \u001B[38;5;241m=\u001B[39m topics[qid]\n\u001B[0;32m    187\u001B[0m         top_ks\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_top_k(query, k, clean\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, qid\u001B[38;5;241m=\u001B[39mqid))\n\u001B[1;32m--> 188\u001B[0m     top_k_fused \u001B[38;5;241m=\u001B[39m \u001B[43mweighted_rrf_fuse\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtop_ks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweights\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mllm_query_fusion_weights\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrrf_k\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrrf_k\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msave_text\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m    189\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m top_k_fused\n\u001B[0;32m    190\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32mD:\\PycharmProjects\\FinalProject\\engine.py:44\u001B[0m, in \u001B[0;36mweighted_rrf_fuse\u001B[1;34m(runs, weights, rrf_k, save_text)\u001B[0m\n\u001B[0;32m     38\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     39\u001B[0m \u001B[38;5;124;03mruns: list[list[Hit]] docids ordered best->worst\u001B[39;00m\n\u001B[0;32m     40\u001B[0m \u001B[38;5;124;03mweights: list[float] same length as runs, defaults to 1/len(runs) each\u001B[39;00m\n\u001B[0;32m     41\u001B[0m \u001B[38;5;124;03msave_text: Save the text field (relevant if this isn't the final step)\u001B[39;00m\n\u001B[0;32m     42\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     43\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;28msum\u001B[39m(weights))\n\u001B[1;32m---> 44\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28msum\u001B[39m(weights) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1.0\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWeights must sum to 1.0\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     45\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m weights \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m     46\u001B[0m     weights \u001B[38;5;241m=\u001B[39m [\u001B[38;5;241m1\u001B[39m\u001B[38;5;241m/\u001B[39m\u001B[38;5;28mlen\u001B[39m(runs)] \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mlen\u001B[39m(runs)\n",
      "\u001B[1;31mAssertionError\u001B[0m: Weights must sum to 1.0"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def compare_rerankers(topics_lists, qrels, reranker_types, rerankers, fusion_weights, query_fusion_weights, rrf_k_queries, rrf_k_reranker):\n",
    "    os.makedirs(f\"Results\",exist_ok=True)\n",
    "    shutil.rmtree(\"Results\")\n",
    "    os.makedirs(f\"Results\",exist_ok=True)\n",
    "    for reranker, reranker_type in zip(rerankers, reranker_types):\n",
    "        save_name = reranker.split('/')[1].replace('-','_')\n",
    "        print(f\"Starting retrieval with reranker {reranker} of type {reranker_type}\")\n",
    "        se = SearchEngine()\n",
    "        se.set_searcher(approach=\"bm25\",fb_terms=20, fb_docs=5, original_query_weight=0.6, mu=340, reranker_type=reranker_type, reranker=reranker)\n",
    "        se.search_all_queries(topics_lists, k=1000, m=50, output_file=f\"run_{save_name}\", rerank_fusion_weights=fusion_weights, llm_query_fusion_weights=query_fusion_weights, rrf_k_queries=rrf_k_queries, rrf_k_reranker=rrf_k_reranker)\n",
    "        for fusion_weight in fusion_weights:\n",
    "            run = load_run(f\"Results/run_{save_name}_rrf_rerank_{fusion_weight}.txt\")\n",
    "            map_score, ap_by_q = mean_average_precision(qrels, run)\n",
    "            print(f\"MAP for reranker {reranker} with rrf {fusion_weight}: {map_score}\")\n",
    "            if reranker is None:\n",
    "                break"
   ],
   "id": "384688bb94f13559",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T16:48:30.794118600Z",
     "start_time": "2026-01-21T16:48:30.778704200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def fuse_rerankers(reranker_type, pre_fusion_weights, post_fusion_weights, topics, rrf_k=60):\n",
    "    \"\"\"\n",
    "    Performs rrf fusion on all the variants of one reranker.\n",
    "    \"\"\"\n",
    "    from processing import Hit\n",
    "    from engine import weighted_rrf_fuse\n",
    "    all_runs = []\n",
    "    for fusion_weight in pre_fusion_weights:\n",
    "        base = load_run(f\"tofuse/run_{reranker_type}_rrf_{fusion_weight}.txt\")\n",
    "        run_hit_format = {}\n",
    "        for qid in base.keys():\n",
    "            run_hit_format[qid]=[Hit(docid=docid, score=0) for docid in base[qid]]\n",
    "        all_runs.append(run_hit_format)\n",
    "\n",
    "    fused = {}\n",
    "    for qid in topics.keys():\n",
    "        fused[qid] = weighted_rrf_fuse([run[qid] for run in all_runs], weights=post_fusion_weights, rrf_k=rrf_k)\n",
    "        with open(f\"Results/fused_fused_rrf_rerank_{rrf_k}.txt\", \"a\", encoding=\"utf-8\") as f:\n",
    "            for rank, hit in enumerate(fused[qid], start=1):\n",
    "                f.write(\n",
    "                    f\"{qid} Q0 {hit.docid} {rank} {hit.score:.6f} run42\\n\"\n",
    "                )\n",
    "\n",
    "    run = load_run(f\"Results/fused_fused_rrf_{rrf_k}.txt\")\n",
    "    map_score, ap_by_q = mean_average_precision(qrels, run)\n",
    "    print(f\"MAP for fusion of rerankers of type {reranker_type} with rrf {rrf_k}: {map_score}\")\n"
   ],
   "id": "8b12627e9aa090a2",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T16:50:20.914856900Z",
     "start_time": "2026-01-21T16:48:30.795119100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# NOTE - fusion_weight = 0 means we take only the reranker, 1 means we take none of the reranker's inputs and it should be identical to pure lexical\n",
    "# For pure lexical only, specify rerankers = [None]\n",
    "# BEST RESULT IS rrf_k = 9\n",
    "#cross-encoder/ms-marco-MiniLM-L-6-v2\" 0.2/0.5\n",
    "#cross-encoder/ms-marco-MiniLM-L12-v2\"\n",
    "# mixedbread-ai/mxbai-rerank-large-v1 0.2\n",
    "# tomaarsen/Qwen3-Reranker-0.6B-seq-cls ??\n",
    "\n",
    "compare_rerankers([topics_subset, topics_expanded_subset, topics_thes], qrels,reranker_types=['CE'], rerankers= [\"cross-encoder/ms-marco-MiniLM-L12-v2\"], fusion_weights=[0, 0.2, 0.5, 0.7, 1], query_fusion_weights=[0.8, 0.2, 0.0], rrf_k_queries=9, rrf_k_reranker=60)\n",
    "# for i in range(3,40,2):\n",
    "#     compare_rerankers([topics_subset, topics_expanded_subset, topics_thes], qrels, [None], fusion_weights=[0, 0.2, 0.5, 0.7, 1], rrf_k=i, should_rerank_embedded=True)\n",
    "\n",
    "#\n",
    "# run = load_run(f\"Results/run_CE_rrf_ariel_hits.txt\")\n",
    "# map_score, ap_by_q = mean_average_precision(qrels, run)\n",
    "# print(f\"MAP is: {map_score}\")\n"
   ],
   "id": "53956a1a50a30c4d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting retrieval with reranker cross-encoder/ms-marco-MiniLM-L12-v2 of type CE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Searching topics: 100%|██████████| 50/50 [01:47<00:00,  2.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP for reranker cross-encoder/ms-marco-MiniLM-L12-v2 with rrf 0: 0.29625210666855206\n",
      "MAP for reranker cross-encoder/ms-marco-MiniLM-L12-v2 with rrf 0.2: 0.2962342651479188\n",
      "MAP for reranker cross-encoder/ms-marco-MiniLM-L12-v2 with rrf 0.5: 0.29880774888197115\n",
      "MAP for reranker cross-encoder/ms-marco-MiniLM-L12-v2 with rrf 0.7: 0.2946468219196829\n",
      "MAP for reranker cross-encoder/ms-marco-MiniLM-L12-v2 with rrf 1: 0.28523687998539804\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "fuse_rerankers('CE', [0, 0.2, 0.5, 0.7, 1], [0.0,0.25,0.25,0.25,0.25], topics_subset, rrf_k=10)",
   "id": "ae38a670aeff00dc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Get LLM datasets and optimize",
   "id": "5c0e0e7d41490218"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from processing import create_llm_generated_queries\n",
    "create_llm_generated_queries(\"Data/LLM_outputs.txt\")"
   ],
   "id": "91eb0cca37b1e1fb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def compare_llm_weights(queries_paths, qrels, rerankers, fusion_weights):\n",
    "    topics_per_path = [load_topics(path) for path in queries_paths]\n",
    "    shutil.rmtree(\"Results\")\n",
    "    os.makedirs(f\"Results\",exist_ok=True)\n",
    "    for reranker in rerankers:\n",
    "        print(f\"Starting retrieval with reranker {reranker}\")\n",
    "        se = SearchEngine()\n",
    "        se.set_searcher(approach=\"bm25\",fb_terms=20, fb_docs=5, original_query_weight=0.6, mu=300, reranker=\"CE\")\n",
    "        se.search_all_queries(topics, k=1000, m=100, output_file=f\"run_{reranker}\", rerank_fusion_weights=0.2)\n",
    "        for fusion_weight in fusion_weights:\n",
    "            run = load_run(f\"Results/run_{reranker}_rrf_{fusion_weight}.txt\")\n",
    "            map_score, ap_by_q = mean_average_precision(qrels, run)\n",
    "            print(f\"MAP for reranker {reranker} with rrf {fusion_weight}: {map_score}\")\n",
    "            if reranker is None:\n",
    "                break\n"
   ],
   "id": "3db1d76bce4e01ca"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Save intermediate results",
   "id": "8eb2c841859830e6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from processing import write_topk_jsonl_query, iter_query_hits\n",
    "def save_inter_results(topics_subset):\n",
    "    se = SearchEngine()\n",
    "    se.set_searcher(approach=\"bm25\",fb_terms=20, fb_docs=5, original_query_weight=0.6, mu=300, reranker=None)\n",
    "    for qid, query in topics_subset.items():\n",
    "        hits = se.get_top_k(query, 1000, clean=True)\n",
    "        write_topk_jsonl_query(hits, \"inter_bm25_rm3.jsonl\", qid)"
   ],
   "id": "99cc7650af1b1fc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "save_inter_results(topics_subset)",
   "id": "aa83bab3b5cca42b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def check_jsonl_results(jsonl_path):\n",
    "    for qid, hits in iter_query_hits(jsonl_path):\n",
    "        with open(f\"Results/jsonl_res.txt\", \"a\", encoding=\"utf-8\") as f:\n",
    "            for rank, hit in enumerate(hits, start=1):\n",
    "                f.write(\n",
    "                    f\"{qid} Q0 {hit.docid} {rank} {hit.score:.6f} {1}\\n\"\n",
    "                )\n",
    "    run = load_run(f\"Results/jsonl_res.txt\")\n",
    "    map_score, ap_by_q = mean_average_precision(qrels, run)\n",
    "    print(f\"MAP is: {map_score}\")"
   ],
   "id": "378e11cc51fcc72d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "check_jsonl_results(\"inter_bm25_rm3.jsonl\")",
   "id": "88a1356ba0b40d5e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": " Extract Train Set Results",
   "id": "174aebcaaa2b0a09"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "HARD_QUERIES =[309, 308, 338, 344, 348, 320, 328, 334, 303, 339] # From EDA",
   "id": "ca1f2f7e5bed7978"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "all_hits = {}\n",
    "hard_hits = {}\n",
    "for i, (qid, topic) in enumerate(topics.items()):\n",
    "    results = se.get_top_k(topic, k=1000, clean=True)\n",
    "    all_hits[f\"{qid}_{topic}\"] = results\n",
    "    if int(qid) in HARD_QUERIES:\n",
    "        hard_hits[f\"{qid}_{topic}\"] = results\n",
    "    if i==49:\n",
    "        print(qid)\n",
    "        break\n",
    "\n",
    "import pickle\n",
    "with open(\"pkls/top1000_rm3_train.pkl\", \"wb\") as f:\n",
    "    pickle.dump(all_hits, f)\n",
    "with open(\"pkls/top1000_rm3_train_hard.pkl\", \"wb\") as f:\n",
    "    pickle.dump(hard_hits, f)"
   ],
   "id": "b8e154a1270b323b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "res",
   "id": "1454236e1223ff22"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# from pyserini.analysis import Analyzer, get_lucene_analyzer\n",
    "# analyzer = get_lucene_analyzer(stemmer='porter', stopwords=False)\n",
    "# se.reader.get_term_counts(\"spanish\",analyzer) #(df,cf)"
   ],
   "id": "4fdaf82062fdf5ff"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# This one creates a file called \"run.txt\" with submitting format, can change file name\n",
    "se.search_all_queries(topics, k=5, m=2, output_file=\"Results/hey.txt\")"
   ],
   "id": "d88df81520a163ec"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "qrels = load_qrels(\"Data/qrels_50_Queries\")   # or \"qrel301.txt\"\n",
    "run   = load_run(\"Results/run.txt\")\n",
    "\n",
    "map_score, ap_by_q = mean_average_precision(qrels, run)\n",
    "map_score"
   ],
   "id": "fa37c828f0d02d2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "stats = se.reader.stats()\n",
    "print(f\"average terms per doc: {stats['total_terms']/stats['documents']}\")"
   ],
   "id": "ad0a1559f12000c7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "doc = se.searcher.doc(\"FT921-3160\")\n",
    "text = doc.raw()\n",
    "text"
   ],
   "id": "ca35d6c9b600edeb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "map = get_map_by_paths(\"Data/qrels_50_Queries\", \"Results/run.txt\")",
   "id": "21e8bab3c2a11942"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "opti = Optimize()\n",
    "# fb_terms_values = [5, 6, 8, 10, 15, 20]\n",
    "# fb_docs_values = [5, 7, 10, 15]\n",
    "# og_query_weight_values = [0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "mus = [200,300,400,500,600,700,800,900,1000,1100,1200]\n",
    "\n",
    "opti.optimize_qld(topics, [20], [5], [0.6], mus, k=1000)"
   ],
   "id": "b3c31bca8b5b012b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
