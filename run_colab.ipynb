{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "231e1bd7b2c528ce",
   "metadata": {},
   "source": [
    "# The Revenge of Rocchio's Angels - COLAB EDITION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52cea1cfa4f2dcf",
   "metadata": {},
   "source": [
    "We will be #1 this time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbd668b",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa445e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
      "Hit:2 https://cli.github.com/packages stable InRelease                         \n",
      "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
      "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [2,302 kB]\n",
      "Hit:5 http://security.ubuntu.com/ubuntu jammy-security InRelease               \n",
      "Hit:6 http://archive.ubuntu.com/ubuntu jammy InRelease                         \n",
      "Hit:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease                 \n",
      "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease   \n",
      "Hit:9 https://r2u.stat.illinois.edu/ubuntu jammy InRelease          \n",
      "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
      "Hit:11 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
      "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
      "Fetched 2,303 kB in 2s (1,494 kB/s)\n",
      "Reading package lists... Done\n",
      "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n"
     ]
    }
   ],
   "source": [
    "# Install OpenJDK 21\n",
    "!apt-get update\n",
    "!apt-get install openjdk-21-jdk-headless -qq > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9b7dea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openjdk version \"21.0.9\" 2025-10-21\n",
      "OpenJDK Runtime Environment (build 21.0.9+10-Ubuntu-122.04)\n",
      "OpenJDK 64-Bit Server VM (build 21.0.9+10-Ubuntu-122.04, mixed mode, sharing)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-21-openjdk-amd64\"\n",
    "!java -version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b73fb38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu126\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
      "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.2.1)\n",
      "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.12/dist-packages (1.13.2)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.24.0+cu126)\n",
      "Requirement already satisfied: pyserini==0.36.0 in /usr/local/lib/python3.12/dist-packages (0.36.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
      "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.2.0)\n",
      "Requirement already satisfied: langchain-text-splitters in /usr/local/lib/python3.12/dist-packages (1.1.0)\n",
      "Requirement already satisfied: Cython>=0.29.21 in /usr/local/lib/python3.12/dist-packages (from pyserini==0.36.0) (3.0.12)\n",
      "Requirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.12/dist-packages (from pyserini==0.36.0) (2.0.2)\n",
      "Requirement already satisfied: pandas>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from pyserini==0.36.0) (2.2.2)\n",
      "Requirement already satisfied: pyjnius>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from pyserini==0.36.0) (1.7.0)\n",
      "Requirement already satisfied: scikit-learn>=0.22.1 in /usr/local/lib/python3.12/dist-packages (from pyserini==0.36.0) (1.6.1)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from pyserini==0.36.0) (1.16.3)\n",
      "Requirement already satisfied: transformers>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from pyserini==0.36.0) (4.57.3)\n",
      "Requirement already satisfied: sentencepiece>=0.1.95 in /usr/local/lib/python3.12/dist-packages (from pyserini==0.36.0) (0.2.1)\n",
      "Requirement already satisfied: nmslib>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from pyserini==0.36.0) (2.1.2)\n",
      "Requirement already satisfied: onnxruntime>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from pyserini==0.36.0) (1.23.2)\n",
      "Requirement already satisfied: lightgbm>=3.3.2 in /usr/local/lib/python3.12/dist-packages (from pyserini==0.36.0) (4.6.0)\n",
      "Requirement already satisfied: spacy>=3.2.1 in /usr/local/lib/python3.12/dist-packages (from pyserini==0.36.0) (3.8.11)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from pyserini==0.36.0) (6.0.3)\n",
      "Requirement already satisfied: openai>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from pyserini==0.36.0) (2.14.0)\n",
      "Requirement already satisfied: tiktoken>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pyserini==0.36.0) (0.12.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from pyserini==0.36.0) (18.1.0)\n",
      "Requirement already satisfied: pillow>=10.2.0 in /usr/local/lib/python3.12/dist-packages (from pyserini==0.36.0) (11.3.0)\n",
      "Requirement already satisfied: pybind11>=2.11.0 in /usr/local/lib/python3.12/dist-packages (from pyserini==0.36.0) (3.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (25.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (0.36.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate) (0.7.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.2)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-text-splitters) (1.2.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.4)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (1.2.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (0.6.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (2.12.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (9.1.2)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (0.13.0)\n",
      "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.8.1->pyserini==0.36.0) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.8.1->pyserini==0.36.0) (25.12.19)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.8.1->pyserini==0.36.0) (5.29.5)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.0.0->pyserini==0.36.0) (4.12.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.0.0->pyserini==0.36.0) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.0.0->pyserini==0.36.0) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.0.0->pyserini==0.36.0) (0.12.0)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai>=1.0.0->pyserini==0.36.0) (1.3.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.4.0->pyserini==0.36.0) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.4.0->pyserini==0.36.0) (2025.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.22.1->pyserini==0.36.0) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.22.1->pyserini==0.36.0) (3.6.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.2.1->pyserini==0.36.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.2.1->pyserini==0.36.0) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.2.1->pyserini==0.36.0) (1.0.15)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.2.1->pyserini==0.36.0) (2.0.13)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.2.1->pyserini==0.36.0) (3.0.12)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.2.1->pyserini==0.36.0) (8.3.10)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.2.1->pyserini==0.36.0) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.2.1->pyserini==0.36.0) (2.5.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.2.1->pyserini==0.36.0) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.2.1->pyserini==0.36.0) (0.4.3)\n",
      "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.2.1->pyserini==0.36.0) (0.21.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken>=0.4.0->pyserini==0.36.0) (2025.11.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.6.0->pyserini==0.36.0) (0.22.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai>=1.0.0->pyserini==0.36.0) (3.11)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai>=1.0.0->pyserini==0.36.0) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai>=1.0.0->pyserini==0.36.0) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.0.0->pyserini==0.36.0) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (3.0.0)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (3.11.5)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (0.25.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.5.0)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy>=3.2.1->pyserini==0.36.0) (1.3.3)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy>=3.2.1->pyserini==0.36.0) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim<1.0.0,>=0.3.0->spacy>=3.2.1->pyserini==0.36.0) (8.3.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy>=3.2.1->pyserini==0.36.0) (0.23.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy>=3.2.1->pyserini==0.36.0) (7.5.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.12/dist-packages (from coloredlogs->onnxruntime>=1.8.1->pyserini==0.36.0) (10.0)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy>=3.2.1->pyserini==0.36.0) (2.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install --extra-index-url https://download.pytorch.org/whl/cu126 accelerate torch python-dotenv faiss-cpu --no-cache torchvision pyserini==0.36.0 python-dotenv tqdm matplotlib seaborn sentence-transformers langchain-text-splitters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c57d294",
   "metadata": {},
   "source": [
    "## All necessary scripts, in the following cells, to use in colab...\n",
    "\n",
    "Not very comfortable but ok"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06389c9",
   "metadata": {},
   "source": [
    "### processing.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5551ebb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from dotenv import load_dotenv\n",
    "import re\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Any, Dict, Optional, Tuple, List, Union\n",
    "from pathlib import Path\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "load_dotenv()\n",
    "SPLITTER_ARGS = {'chunk_size': 768, 'chunk_overlap': 50}\n",
    "SPLITTER_SINGLETON = RecursiveCharacterTextSplitter(**SPLITTER_ARGS)\n",
    "\n",
    "# Generic SGML-ish block: <TAG ...> ... </TAG>\n",
    "# TAG names: letters/digits/_/-\n",
    "_BLOCK = re.compile(\n",
    "    r\"<(?P<tag>[A-Za-z][A-Za-z0-9_-]*)(?P<attrs>\\s+[^>]*)?>\\s*(?P<content>.*?)\\s*</(?P=tag)>\",\n",
    "    re.DOTALL\n",
    ")\n",
    "\n",
    "# Remove any remaining tags (inline or otherwise)\n",
    "_ANY_TAG = re.compile(r\"</?[^>]+>\")\n",
    "\n",
    "# Common “annotation-like” remnants you may want to drop from body\n",
    "_TEXT_MARKER = re.compile(r\"^\\s*\\[Text\\]\\s*\", re.IGNORECASE)\n",
    "\n",
    "@dataclass(slots=True)\n",
    "class Hit:\n",
    "    docid: str\n",
    "    score: float\n",
    "    qid: Optional[int] = None\n",
    "    query: Optional[str] = None\n",
    "    text: Optional[str] = None\n",
    "    meta: Dict[str, Any] = field(default_factory=dict)\n",
    "\n",
    "    def __getattr__(self, name: str):\n",
    "        try:\n",
    "            return self.meta[name]\n",
    "        except KeyError:\n",
    "            raise AttributeError(name)\n",
    "\n",
    "    # For LangChain\n",
    "    @property\n",
    "    def page_content(self) -> str:\n",
    "        return self.text\n",
    "\n",
    "    @property\n",
    "    def metadata(self) -> dict:\n",
    "        return {\"docid\": self.docid, \"query\": self.query, **self.meta}\n",
    "\n",
    "\n",
    "\n",
    "def create_llm_generated_queries(\n",
    "    input_path: str | Path,\n",
    "    out_paths: List[str | Path] | None = None,\n",
    "    expected_cols: int = 3,\n",
    "    sep: str = \" \",\n",
    "    encoding: str = \"utf-8\",\n",
    ") -> Tuple[Path, ...]:\n",
    "    \"\"\"\n",
    "    Read The query permutations generated by the llm:\n",
    "        <qid>: option1, option2, option3, ...\n",
    "    and write N separate TREC query files (one per option/\"column\"):\n",
    "        qid<tab>option_i\n",
    "    \"\"\"\n",
    "    input_path = Path(input_path)\n",
    "    if out_paths is None:\n",
    "        out_paths = [Path(f\"queries_col{i+1}.txt\") for i in range(expected_cols)]\n",
    "    else:\n",
    "        out_paths = [Path(p) for p in out_paths]\n",
    "\n",
    "    columns: List[List[str]] = [[] for _ in range(expected_cols)]\n",
    "\n",
    "    with input_path.open(\"r\", encoding=encoding) as f:\n",
    "        for line_no, raw in enumerate(f, start=1):\n",
    "            line = raw.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "\n",
    "            if \":\" not in line:\n",
    "                raise ValueError(f\"Malformed line {line_no}: missing ':' -> {line!r}\")\n",
    "\n",
    "            qid, rest = line.split(\":\", 1)\n",
    "            qid = qid.strip()\n",
    "            if not qid:\n",
    "                raise ValueError(f\"Malformed line {line_no}: empty qid -> {line!r}\")\n",
    "\n",
    "            options = [opt.strip() for opt in rest.split(\",\") if opt.strip() != \"\"]\n",
    "            if len(options) != expected_cols:\n",
    "                raise ValueError(\n",
    "                    f\"Line {line_no} (qid={qid}) has {len(options)} options, expected {expected_cols}: {line!r}\"\n",
    "                )\n",
    "\n",
    "            for i in range(expected_cols):\n",
    "                columns[i].append(f\"{qid}{sep}{options[i]}\")\n",
    "\n",
    "    for out_path in out_paths:\n",
    "        out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for out_path, lines in zip(out_paths, columns):\n",
    "        out_path.write_text(\"\\n\".join(lines) + (\"\\n\" if lines else \"\"), encoding=encoding)\n",
    "\n",
    "    return tuple(out_paths)\n",
    "\n",
    "def write_topk_jsonl_query(hits, out_path, qid):\n",
    "    \"\"\"\n",
    "    Appends one JSONL record:\n",
    "      {\"query\": \"<query or qid>\", \"hits\": [{\"docid\": \"...\", \"score\": ...}, ...]}\n",
    "    For retrieval checkpointing.\n",
    "    \"\"\"\n",
    "    if not hits:\n",
    "        return\n",
    "    out_path = Path(out_path)\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    query = hits[0].query\n",
    "    seen = set()\n",
    "    hit_list = []\n",
    "\n",
    "    for h in hits:\n",
    "        # defensive: ensure single-query invariant\n",
    "        if h.query != query:\n",
    "            raise ValueError(\"Hits contain multiple queries\")\n",
    "\n",
    "        if h.docid in seen:\n",
    "            print(\"DUPLICATE (HOW?)\")\n",
    "            continue\n",
    "\n",
    "        seen.add(h.docid)\n",
    "        hit_list.append({\n",
    "            \"docid\": str(h.docid),\n",
    "            \"score\": float(h.score),\n",
    "            \"text\": str(h.text),\n",
    "        })\n",
    "\n",
    "    rec = {\n",
    "        \"query\": query,\n",
    "        \"qid\": qid,\n",
    "        \"hits\": hit_list,\n",
    "    }\n",
    "\n",
    "    with out_path.open(\"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(json.dumps(rec, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "\n",
    "def iter_query_hits(jsonl_path: str | Path):\n",
    "    \"\"\"\n",
    "    Stream a JSONL file line-by-line to yield previous resutls.\n",
    "    \"\"\"\n",
    "    jsonl_path = Path(jsonl_path)\n",
    "\n",
    "    with jsonl_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        for line_no, line in enumerate(f, start=1):\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                rec = json.loads(line)\n",
    "            except json.JSONDecodeError as e:\n",
    "                raise ValueError(f\"Bad JSON on line {line_no} in {jsonl_path}\") from e\n",
    "\n",
    "            q = rec[\"query\"]\n",
    "            hits_raw = rec.get(\"hits\", [])\n",
    "            hits = [Hit(query=q, docid=str(h[\"docid\"]), score=float(h[\"score\"])) for h in hits_raw]\n",
    "\n",
    "            yield rec[\"qid\"], hits\n",
    "\n",
    "\n",
    "def _normalize_ws(s: str) -> str:\n",
    "    s = s.replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\")\n",
    "    # Collapse spaces/tabs\n",
    "    s = re.sub(r\"[ \\t]+\", \" \", s)\n",
    "    # Collapse many blank lines\n",
    "    s = re.sub(r\"\\n{3,}\", \"\\n\\n\", s)\n",
    "    return s.strip()\n",
    "\n",
    "def clean_inner_text(s: str) -> str:\n",
    "    \"\"\"\n",
    "    Cleans text inside a tag:\n",
    "    - strips any nested tags like <F P=105> ... </F>\n",
    "    - removes [Text] marker (common in newswire)\n",
    "    - normalizes whitespace\n",
    "    \"\"\"\n",
    "    s = _ANY_TAG.sub(\"\", s)  # drop nested tags\n",
    "    s = _TEXT_MARKER.sub(\"\", s)  # drop leading [Text] marker\n",
    "    return _normalize_ws(s)\n",
    "\n",
    "def clean_robust(raw) -> Tuple[str, Dict[str, Union[str, List[str]]]]:\n",
    "    \"\"\"\n",
    "    Extract ALL SGML-ish blocks.\n",
    "      - <TEXT> blocks become the main body (concatenate if multiple)\n",
    "      - every other tag becomes metadata[tag] (string or list of strings)\n",
    "    Anything not inside blocks is ignored by default\n",
    "    \"\"\"\n",
    "    metadata: Dict[str, Any] = {}\n",
    "    body_parts: List[str] = []\n",
    "    if not raw:\n",
    "        return \"\", metadata\n",
    "\n",
    "    # Find all blocks\n",
    "    for m in _BLOCK.finditer(raw):\n",
    "        tag = m.group(\"tag\").strip().upper()\n",
    "        content = m.group(\"content\") or \"\"\n",
    "        cleaned = clean_inner_text(content)\n",
    "\n",
    "        if not cleaned:\n",
    "            continue\n",
    "\n",
    "        if tag == \"TEXT\":\n",
    "            body_parts.append(cleaned)\n",
    "        else:\n",
    "            # store possibly repeated tags as list\n",
    "            if tag in metadata:\n",
    "                if isinstance(metadata[tag], list):\n",
    "                    metadata[tag].append(cleaned)\n",
    "                else:\n",
    "                    metadata[tag] = [metadata[tag], cleaned]\n",
    "            else:\n",
    "                metadata[tag] = cleaned\n",
    "\n",
    "    # If there was no <TEXT> tag, fall back to cleaning the whole raw as body\n",
    "    # (useful when some corpora omit TEXT)\n",
    "    if not body_parts:\n",
    "        # Remove all blocks completely, then clean what remains\n",
    "        stripped = _BLOCK.sub(\"\", raw)\n",
    "        stripped = clean_inner_text(stripped)\n",
    "        return stripped, metadata\n",
    "\n",
    "    body = \"\\n\\n\".join(body_parts)\n",
    "    return body, metadata\n",
    "\n",
    "def split_passages(hits: List[Hit], splitter=SPLITTER_SINGLETON):\n",
    "    return splitter.split_documents(hits)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1215f6f",
   "metadata": {},
   "source": [
    "### engine.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ab68812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "#os.environ[\"JAVA_HOME\"] = os.getenv(\"JAVA_HOME\")\n",
    "from tqdm import tqdm\n",
    "from pyserini.index.lucene import IndexReader\n",
    "from pyserini.search.lucene import LuceneSearcher\n",
    "#from processing import split_passages, clean_robust, Hit\n",
    "from sentence_transformers import CrossEncoder\n",
    "# from mxbai_rerank import MxbaiRerankV2\n",
    "# from inranker import T5Ranker\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(DEVICE)\n",
    "CROSS_ENCODER = os.getenv(\"CROSS_ENCODER\")\n",
    "SUPPORTED_RERANKERS = [\"CE\", \"QWEN_CE\", \"mxbai\", \"monot5\", \"twolar\", \"inranker\"]\n",
    "\n",
    "\n",
    "def format_queries(query, instruction=None):\n",
    "    prefix = '<|im_start|>system\\nJudge whether the Document meets the requirements based on the Query and the Instruct provided. Note that the answer can only be \"yes\" or \"no\".<|im_end|>\\n<|im_start|>user\\n'\n",
    "    if instruction is None:\n",
    "        instruction = (\n",
    "            \"Given a web search query, retrieve relevant passages that answer the query\"\n",
    "        )\n",
    "    return f\"{prefix}<Instruct>: {instruction}\\n<Query>: {query}\\n\"\n",
    "\n",
    "\n",
    "def format_document(document):\n",
    "    suffix = \"<|im_end|>\\n<|im_start|>assistant\\n<think>\\n\\n</think>\\n\\n\"\n",
    "    return f\"<Document>: {document}{suffix}\"\n",
    "\n",
    "\n",
    "def weighted_rrf_fuse(runs, weights=None, rrf_k=60, save_text=False):\n",
    "    \"\"\"\n",
    "    runs: list[list[Hit]] docids ordered best->worst\n",
    "    weights: list[float] same length as runs, defaults to 1/len(runs) each\n",
    "    save_text: Save the text field (relevant if this isn't the final step)\n",
    "    \"\"\"\n",
    "    assert sum(weights) == 1.0, \"Weights must sum to 1.0\"\n",
    "    if weights is None:\n",
    "        weights = [1/len(runs)] * len(runs)\n",
    "    scores = defaultdict(float)\n",
    "    texts = defaultdict(str)\n",
    "    for run, w in zip(runs, weights):\n",
    "        for rank, hit in enumerate(run, start=1):\n",
    "            scores[hit.docid] += w * (1.0 / (rrf_k + rank))\n",
    "            texts[hit.docid] = hit.text if save_text else None\n",
    "\n",
    "    fused = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    return [Hit(docid=docid, score=score, text=texts[docid]) for docid, score in fused]\n",
    "\n",
    "\n",
    "\n",
    "class Reranker:\n",
    "    def __init__(self, reranker_type, cross_encoder_name=None, device=DEVICE):\n",
    "        self.reranker_type = reranker_type\n",
    "        self.model_name = cross_encoder_name if cross_encoder_name else CROSS_ENCODER\n",
    "        if self.reranker_type not in SUPPORTED_RERANKERS:\n",
    "            raise ValueError(f\"reranker_type must be in {SUPPORTED_RERANKERS}\")\n",
    "        if self.reranker_type == 'CE':\n",
    "            self.model = CrossEncoder(self.model_name, device=DEVICE)\n",
    "\n",
    "        elif self.reranker_type == 'QWEN_CE':\n",
    "            self.model = CrossEncoder(self.model_name, device=DEVICE)\n",
    "        # elif self.reranker_type == 'mxbai':\n",
    "        #     self.model = MxbaiRerankV2(\"mixedbread-ai/mxbai-rerank-large-v2\", device=device)\n",
    "        #     print(device)\n",
    "        #     self.model.to(device)\n",
    "        # elif self.reranker_type == \"inranker\":\n",
    "        #     self.model = T5Ranker(model_name_or_path=\"unicamp-dl/InRanker-3B\", device=device)\n",
    "        #     print(device)\n",
    "        else:\n",
    "            raise NotImplementedError(\"Type not implemented yet sry :(\")\n",
    "\n",
    "    def rerank(self, query, retrieval_candidates, max_weight=0.8):\n",
    "        def _remove_whitespaces(text):\n",
    "            WS_NEWLINES = re.compile(r\"\\s*\\n\\s*\")\n",
    "            WS_SPACES = re.compile(r\"[ \\t]+\")\n",
    "            text = WS_NEWLINES.sub(\" \", text)\n",
    "            text = WS_SPACES.sub(\" \", text)\n",
    "            return text\n",
    "        def _collated_doc_score(scores, max_weight=0.8):\n",
    "            return max(scores) * max_weight + (1 - max_weight) * (sum(scores) - max(scores)) / (len(scores) - 1) if len(scores) > 1 else max(scores)\n",
    "\n",
    "        cleaned_docs = [_remove_whitespaces(doc.page_content) for doc in retrieval_candidates]\n",
    "        per_doc_scores = defaultdict(list)\n",
    "\n",
    "        if self.reranker_type == 'CE':\n",
    "            pairs = [[query, cleaned_doc] for cleaned_doc in cleaned_docs]\n",
    "            cross_scores = self.model.predict(pairs)\n",
    "            for score, doc in zip(cross_scores, retrieval_candidates):\n",
    "                per_doc_scores[doc.metadata['docid']].append(score)\n",
    "\n",
    "        if self.reranker_type == 'mxbai':\n",
    "            id2doc = {i:doc.metadata['docid'] for i, doc in enumerate(retrieval_candidates)}\n",
    "            cross_scores = self.model.rank(query, cleaned_docs, return_documents=False)\n",
    "            for score in cross_scores:\n",
    "                per_doc_scores[id2doc[score.index]].append(score.score)\n",
    "\n",
    "        if self.reranker_type == 'inranker':\n",
    "            id2doc = {i: doc.metadata['docid'] for i, doc in enumerate(retrieval_candidates)}\n",
    "            scores = self.model.get_scores(\n",
    "                query=query,\n",
    "                docs=cleaned_docs\n",
    "            )\n",
    "            # Scores are sorted in descending order (most relevant to least)\n",
    "            # scores -> [0, 1]\n",
    "            sorted_scores = sorted(zip(scores, cleaned_docs), key=lambda x: x[0], reverse=True)\n",
    "            for i,(score,_) in sorted_scores:\n",
    "                per_doc_scores[id2doc[i]].append(score)\n",
    "\n",
    "        if self.reranker_type == 'QWEN_CE':\n",
    "            task = \"Given a web search query, retrieve relevant passages that answer the query\"\n",
    "            queries = [query]*len(cleaned_docs)\n",
    "            pairs = [\n",
    "                [format_queries(query, task), format_document(doc)]\n",
    "                for query, doc in zip(queries,cleaned_docs)\n",
    "            ]\n",
    "            cross_scores = self.model.predict(pairs)\n",
    "            for score, doc in zip(cross_scores, retrieval_candidates):\n",
    "                per_doc_scores[doc.metadata['docid']].append(score)\n",
    "\n",
    "\n",
    "        collated_doc_scores = {}\n",
    "        for docid, scores in per_doc_scores.items():\n",
    "            collated_doc_scores[docid] = _collated_doc_score(scores, max_weight=max_weight)\n",
    "        ranked = sorted(collated_doc_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "        return [Hit(docid=doc[0], score=doc[1]) for doc in ranked]\n",
    "\n",
    "\n",
    "\n",
    "class SearchEngine:\n",
    "    def __init__(self):\n",
    "        self.reader = IndexReader.from_prebuilt_index('robust04')\n",
    "        self.searcher = LuceneSearcher.from_prebuilt_index('robust04')\n",
    "        self.reranker = None\n",
    "\n",
    "    def set_searcher(self, approach=\"qld\", fb_terms=5, fb_docs=10, original_query_weight=0.8, mu=1000,\n",
    "                     reranker_type='CE', reranker=CROSS_ENCODER):\n",
    "        if approach==\"qld\":\n",
    "            # Setting query likelihood with dirichlet prior\n",
    "            self.searcher.set_qld(mu=mu)\n",
    "            # Setting RM3 expanding the query, with a safe alpha\n",
    "            self.searcher.set_rm3(fb_terms=fb_terms, fb_docs=fb_docs, original_query_weight=original_query_weight)\n",
    "        elif approach==\"bm25\":\n",
    "            self.searcher.set_bm25(k1=0.5, b=0.36)\n",
    "            self.searcher.set_rm3(fb_terms=fb_terms,fb_docs=fb_docs,original_query_weight=original_query_weight)\n",
    "        if reranker is not None:\n",
    "            self.reranker = Reranker(reranker_type,cross_encoder_name=reranker)\n",
    "\n",
    "    def get_top_k(self, query, k=5, clean=True, qid=None):\n",
    "        \"\"\"\n",
    "        Get the top k ranked (full) documents using the searcher\n",
    "        :param query: the query\n",
    "        :param k: top results to retrieve (default: 5)\n",
    "        :param clean: Whether to clean the retrieved docs and extract metadata (default: True)\n",
    "        :param qid: query id\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        context = []\n",
    "        hits = self.searcher.search(query, k)\n",
    "        # Get text from hits\n",
    "        for hit in hits:\n",
    "            doc = self.searcher.doc(hit.docid)\n",
    "            raw_doc = doc.raw()\n",
    "            if clean:\n",
    "                cleaned_doc, doc_metadata = clean_robust(raw_doc)\n",
    "                context.append(Hit(qid=qid, query=query, docid=hit.docid, score=hit.score, meta=doc_metadata, text=cleaned_doc))\n",
    "            else:\n",
    "                context.append(Hit(qid=qid, query=query, docid=hit.docid, score=hit.score, text=raw_doc))\n",
    "        return context\n",
    "\n",
    "\n",
    "    def multi_query_fuse(self, qid, topics_list, llm_query_fusion_weights, k=1000, rrf_k=60):\n",
    "        top_ks = []\n",
    "        assert len(llm_query_fusion_weights) == len(topics_list), \"Weight & lists mismatch\"\n",
    "        if len(topics_list) > 1:\n",
    "            for i, topics in enumerate(topics_list):\n",
    "                if llm_query_fusion_weights[i] == 0:\n",
    "                    continue\n",
    "                query = topics[qid]\n",
    "                top_ks.append(self.get_top_k(query, k, clean=True, qid=qid))\n",
    "            top_k_fused = weighted_rrf_fuse(top_ks, weights=llm_query_fusion_weights, rrf_k=rrf_k, save_text=True)\n",
    "            return top_k_fused\n",
    "        else:\n",
    "            return self.get_top_k(topics_list[0][qid], k, clean=True, qid=qid)\n",
    "\n",
    "    def retrieve_rerank(self, query, hits, m=100, fusion_weights=None, rrf_k=60):\n",
    "        top_m = hits[:m]\n",
    "        passages_top_m = split_passages(top_m)\n",
    "        if self.reranker:\n",
    "            top_m_reranked = self.reranker.rerank(query, passages_top_m)\n",
    "            top_m_fused_permutations = [weighted_rrf_fuse([top_m_reranked, top_m], weights=[1-fusion_weight,fusion_weight], rrf_k=rrf_k) for fusion_weight in fusion_weights]\n",
    "            all_docs_reranked = [top_m_fused + hits[m:] for top_m_fused in top_m_fused_permutations]\n",
    "            return all_docs_reranked\n",
    "        else:\n",
    "            return [hits]\n",
    "\n",
    "\n",
    "    def search_and_write_trec_run(self, query, k, topic_id, run_tag, output_file, fusion_weights=None,\n",
    "                                  query_weights=None,\n",
    "                                  topics_lists=None,\n",
    "                                  m=100,\n",
    "                                  rrf_k_queries=9,\n",
    "                                  rrf_k_reranker=60):\n",
    "        if fusion_weights is None:\n",
    "            fusion_weights = [0]\n",
    "        assert k >= m, \"initial retrieval k must be bigger-equal than fine reranker m\"\n",
    "        hits = self.multi_query_fuse(topic_id, topics_lists, query_weights, k=k, rrf_k=rrf_k_queries)  # Hits are score-sorted by default\n",
    "        hits_per_fusion_weight = self.retrieve_rerank(query, hits, m, fusion_weights, rrf_k=rrf_k_reranker)\n",
    "        for i, hits in enumerate(hits_per_fusion_weight):\n",
    "            with open(f\"Results/{output_file}_rrf_{fusion_weights[i]}.txt\", \"a\", encoding=\"utf-8\") as f:\n",
    "                for rank, hit in enumerate(hits, start=1):\n",
    "                    f.write(\n",
    "                        f\"{topic_id} Q0 {hit.docid} {rank} {hit.score:.6f} {run_tag}\\n\"\n",
    "                    )\n",
    "\n",
    "\n",
    "\n",
    "    def search_all_queries(self, topics_lists, k=1000, run_tag=\"run1\", output_file=\"run.txt\", m=100,\n",
    "                           llm_query_fusion_weights=None,\n",
    "                           rerank_fusion_weights=None,\n",
    "                           rrf_k_queries=9,\n",
    "                           rrf_k_reranker=60):\n",
    "        \"\"\"\n",
    "        Search all queries according to topics list\n",
    "        :param topics_lists: list of [(query id, query] for topic in topics. Each topic is taken form a .txt listing all queries.\n",
    "        :param k: top results to retrieve (default: 1000)\n",
    "        :param run_tag: name of run to write as the format\n",
    "        :param output_file: name of outputfile (default: run.txt)\n",
    "        :param m: reranking threshold (default: 100)\n",
    "        :param llm_query_fusion_weights: list of fusion weights on multiple query ablations (default: [1,0...,0])\n",
    "        :param rerank_fusion_weights: rrf weights to experiment with (default: 0)\n",
    "        :param rrf_k_queries: Query fusion RRF constant\n",
    "        :param rrf_k_reranker: RRF reranking constant\n",
    "        \"\"\"\n",
    "        if rerank_fusion_weights is None:\n",
    "            rerank_fusion_weights = [0]\n",
    "        if llm_query_fusion_weights is None:\n",
    "            llm_query_fusion_weights = [1]+[0]*(len(topics_lists) - 1)\n",
    "        for qid, query in tqdm(topics_lists[0].items(), desc=\"Searching topics\"):\n",
    "            self.search_and_write_trec_run(query, k, qid, run_tag, output_file, m=m,\n",
    "                                           fusion_weights=rerank_fusion_weights, query_weights=llm_query_fusion_weights,\n",
    "                                           topics_lists=topics_lists, rrf_k_queries=rrf_k_queries, rrf_k_reranker=rrf_k_reranker)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc82004",
   "metadata": {},
   "source": [
    "### evaluate_map.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2da9b24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from typing import Dict, List, Tuple, Iterable, Optional\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def load_qrels(qrels_path: str) -> Dict[str, Dict[str, int]]:\n",
    "    \"\"\"\n",
    "    qrels line format (TREC):\n",
    "      qid  unused  docid  rel\n",
    "    Example:\n",
    "      301  0       FBIS3-10555  0\n",
    "    \"\"\"\n",
    "    qrels = defaultdict(dict)\n",
    "    with open(qrels_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            qid, _unused, docid, rel = line.split()[:4]\n",
    "            qrels[qid][docid] = int(rel)\n",
    "    return qrels\n",
    "\n",
    "def load_run(run_path: str) -> Dict[str, List[str]]:\n",
    "    \"\"\"\n",
    "    run line format (TREC run file):\n",
    "      qid  Q0  docid  rank  score  tag\n",
    "    We will sort by rank (int) to be safe.\n",
    "    \"\"\"\n",
    "    run = defaultdict(list)  # qid -> list[(rank, docid)]\n",
    "    with open(run_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            parts = line.split()\n",
    "            qid, _q0, docid, rank = parts[0], parts[1], parts[2], parts[3]\n",
    "            run[qid].append((int(rank), docid))\n",
    "    # sort by rank then keep docids\n",
    "    out = {}\n",
    "    for qid, lst in run.items():\n",
    "        lst.sort(key=lambda x: x[0])\n",
    "        out[qid] = [docid for _, docid in lst]\n",
    "    return out\n",
    "\n",
    "\n",
    "def average_precision(ranked_docids: List[str], qrels_for_q: Dict[str, int]) -> float:\n",
    "    \"\"\"\n",
    "    AP(q) = average over precisions at ranks where a relevant document is found.\n",
    "    Relevant is rel > 0. Unjudged docs are treated as non-relevant.\n",
    "    Denominator is #relevant judged docs for that query.\n",
    "    \"\"\"\n",
    "    rel_set = {docid for docid, rel in qrels_for_q.items() if rel > 0}\n",
    "    if not rel_set:\n",
    "        return 0.0\n",
    "\n",
    "    hits = 0\n",
    "    sum_prec = 0.0\n",
    "    for i, docid in enumerate(ranked_docids, start=1):\n",
    "        if docid in rel_set:\n",
    "            hits += 1\n",
    "            sum_prec += hits / i\n",
    "    return sum_prec / len(rel_set)\n",
    "\n",
    "\n",
    "def mean_average_precision(\n",
    "    qrels: Dict[str, Dict[str, int]],\n",
    "    run: Dict[str, List[str]],\n",
    "    qids: Optional[Iterable[str]] = None\n",
    ") -> Tuple[float, Dict[str, float]]:\n",
    "    \"\"\"\n",
    "    Returns (MAP, per_query_AP_dict).\n",
    "    If qids is None: evaluate intersection of qrels and run query ids.\n",
    "    \"\"\"\n",
    "    if qids is None:\n",
    "        eval_qids = sorted(set(qrels.keys()) & set(run.keys()), key=lambda x: int(x) if x.isdigit() else x)\n",
    "    else:\n",
    "        eval_qids = [str(q) for q in qids]\n",
    "\n",
    "    ap_by_q = {}\n",
    "    ap_values = []\n",
    "    for qid in eval_qids:\n",
    "        ap = average_precision(run.get(qid, []), qrels.get(qid, {}))\n",
    "        ap_by_q[qid] = ap\n",
    "        ap_values.append(ap)\n",
    "\n",
    "    map_score = sum(ap_values) / len(ap_values) if ap_values else 0.0\n",
    "    return map_score, ap_by_q\n",
    "\n",
    "def get_map_by_paths(qrels_path, run_path):\n",
    "    qrels = load_qrels(qrels_path)  # or \"qrel301.txt\"\n",
    "    run = load_run(run_path)\n",
    "\n",
    "    map_score, ap_by_q = mean_average_precision(qrels, run)\n",
    "    return map_score\n",
    "\n",
    "def load_topics(path):\n",
    "    \"\"\"\n",
    "    Input format:\n",
    "    qid<TAB>query text\n",
    "    \"\"\"\n",
    "    topics = {}\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            qid, query = line.split(\"\\t\", 1)\n",
    "            topics[qid] = query\n",
    "    return topics\n",
    "\n",
    "\n",
    "def precision_at_k(ranked_docids, qrels_for_q, k):\n",
    "    rel_set = {d for d, rel in qrels_for_q.items() if rel > 0}\n",
    "    if not ranked_docids:\n",
    "        return 0.0\n",
    "    return sum(1 for d in ranked_docids[:k] if d in rel_set) / k\n",
    "\n",
    "\n",
    "def recall_at_k(ranked_docids, qrels_for_q, k):\n",
    "    rel_set = {d for d, rel in qrels_for_q.items() if rel > 0}\n",
    "    if not rel_set:\n",
    "        return 0.0\n",
    "    return sum(1 for d in ranked_docids[:k] if d in rel_set) / len(rel_set)\n",
    "\n",
    "\n",
    "def max_ap_at_k(qrels_for_q: Dict[str, int], k: int) -> float:\n",
    "    rel_count = sum(1 for _, rel in qrels_for_q.items() if rel > 0)\n",
    "    if rel_count == 0:\n",
    "        return 0.0\n",
    "    return min(rel_count, k) / rel_count\n",
    "\n",
    "\n",
    "def first_relevant_rank_at_k(ranked_docids: List[str], qrels_for_q: Dict[str, int], k: int) -> int:\n",
    "    rel_set = {d for d, rel in qrels_for_q.items() if rel > 0}\n",
    "    if not rel_set:\n",
    "        return 0  # no relevant docs judged for this query\n",
    "    for i, docid in enumerate(ranked_docids[:k], start=1):\n",
    "        if docid in rel_set:\n",
    "            return i\n",
    "    return 0  # none found within top-k\n",
    "\n",
    "\n",
    "def reciprocal_rank_at_k(ranked_docids: List[str], qrels_for_q: Dict[str, int], k: int) -> float:\n",
    "    r = first_relevant_rank_at_k(ranked_docids, qrels_for_q, k)\n",
    "    return 1.0 / r if r > 0 else 0.0\n",
    "\n",
    "\n",
    "def evaluate_run(\n",
    "    qrels: Dict[str, Dict[str, int]],\n",
    "    run: Dict[str, List[str]],\n",
    "    name: str,                 # stored in df.attrs[\"name\"]\n",
    "    ks=range(100, 1001, 100),\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Long format: one row per k.\n",
    "    Columns: k, MAP, P, Recall, MaxAP, FirstRel, MRR\n",
    "    Run identity stored as df.attrs[\"name\"].\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "\n",
    "    for k in ks:\n",
    "        ap_vals, p_vals, r_vals, max_ap_vals = [], [], [], []\n",
    "        first_vals, rr_vals = [], []\n",
    "\n",
    "        for qid, qrels_for_q in qrels.items():\n",
    "            ranked = run.get(qid, [])[:k]\n",
    "\n",
    "            ap_vals.append(average_precision(ranked, qrels_for_q))\n",
    "            p_vals.append(precision_at_k(ranked, qrels_for_q, k))\n",
    "            r_vals.append(recall_at_k(ranked, qrels_for_q, k))\n",
    "            max_ap_vals.append(max_ap_at_k(qrels_for_q, k))\n",
    "\n",
    "            fr = first_relevant_rank_at_k(ranked, qrels_for_q, k)\n",
    "            first_vals.append(fr)\n",
    "            rr_vals.append(1.0 / fr if fr > 0 else 0.0)\n",
    "\n",
    "        rows.append({\n",
    "            \"k\": int(k),\n",
    "            \"MAP\": sum(ap_vals) / len(ap_vals),\n",
    "            \"P\": sum(p_vals) / len(p_vals),\n",
    "            \"Recall\": sum(r_vals) / len(r_vals),\n",
    "            \"MaxAP\": sum(max_ap_vals) / len(max_ap_vals),\n",
    "            \"FirstRel\": sum(first_vals) / len(first_vals),  # mean first relevant rank (0 if none)\n",
    "            \"MRR\": sum(rr_vals) / len(rr_vals),            # mean reciprocal rank@k\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.attrs[\"name\"] = name\n",
    "    return df\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7610707",
   "metadata": {},
   "source": [
    "## Actual Scripting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d0a2ca9a03cf42",
   "metadata": {},
   "source": [
    "Local Script Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c825986b6b636d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T12:25:24.940965Z",
     "start_time": "2026-01-21T12:25:16.171252300Z"
    }
   },
   "outputs": [],
   "source": [
    "# from engine import SearchEngine\n",
    "# from evaluate_map import *\n",
    "# from optimizing import Optimize\n",
    "import shutil\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a35960143bab9e1",
   "metadata": {},
   "source": [
    "Full (Current) Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f62b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a173077a3f23ac69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T12:25:24.986159Z",
     "start_time": "2026-01-21T12:25:24.941965400Z"
    }
   },
   "outputs": [],
   "source": [
    "topics = load_topics(\"Data/queriesROBUST.txt\")\n",
    "topics_expanded = load_topics(\"Data/chatExpandedQueries.txt\")\n",
    "topics_thes = load_topics(\"Data/chatQueries.txt\")\n",
    "qrels = load_qrels(\"Data/qrels_50_Queries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bf748809b6adc46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T12:25:25.000159200Z",
     "start_time": "2026-01-21T12:25:24.987158700Z"
    }
   },
   "outputs": [],
   "source": [
    "def subset_topics(topics, qids_list):\n",
    "    topics_subset = {\n",
    "        k: v\n",
    "        for k, v in topics.items()\n",
    "        if int(k) in qids_list\n",
    "    }\n",
    "    return topics_subset\n",
    "\n",
    "train_qids = list(range(301,351))\n",
    "HARD_QUERIES =[309, 308, 338, 344, 348, 320, 328, 334, 303, 339] # From EDA, queries with low amounts of relevant documents.\n",
    "topics_subset = subset_topics(topics, train_qids)\n",
    "topics_expanded_subset = subset_topics(topics_expanded, train_qids)\n",
    "topics_thes_subset = subset_topics(topics_thes, train_qids)\n",
    "\n",
    "topics_hard = subset_topics(topics, HARD_QUERIES)\n",
    "topics_expanded_hard = subset_topics(topics_expanded, HARD_QUERIES)\n",
    "topics_thes_hard = subset_topics(topics_thes, HARD_QUERIES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "384688bb94f13559",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T12:25:25.015768Z",
     "start_time": "2026-01-21T12:25:25.001160200Z"
    }
   },
   "outputs": [],
   "source": [
    "def compare_rerankers(topics_lists, qrels, reranker_type, rerankers, fusion_weights, query_fusion_weights, rrf_k_queries, rrf_k_reranker):\n",
    "    os.makedirs(f\"Results\",exist_ok=True)\n",
    "    shutil.rmtree(\"Results\")\n",
    "    os.makedirs(f\"Results\",exist_ok=True)\n",
    "    for reranker in rerankers:\n",
    "        save_name = reranker.split('/')[1].replace('-','_')\n",
    "        print(f\"Starting retrieval with reranker {reranker}\")\n",
    "        se = SearchEngine()\n",
    "        se.set_searcher(approach=\"bm25\",fb_terms=20, fb_docs=5, original_query_weight=0.6, mu=340, reranker_type=reranker_type, reranker=reranker)\n",
    "        se.search_all_queries(topics_lists, k=1000, m=50, output_file=f\"run_{save_name}\", rerank_fusion_weights=fusion_weights, llm_query_fusion_weights=query_fusion_weights, rrf_k_queries=rrf_k_queries, rrf_k_reranker=rrf_k_reranker)\n",
    "        for fusion_weight in fusion_weights:\n",
    "            run = load_run(f\"Results/run_{save_name}_rrf_{fusion_weight}.txt\")\n",
    "            map_score, ap_by_q = mean_average_precision(qrels, run)\n",
    "            print(f\"MAP for reranker {reranker} with rrf {fusion_weight}: {map_score}\")\n",
    "            if reranker is None:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b12627e9aa090a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T12:25:25.031902500Z",
     "start_time": "2026-01-21T12:25:25.016769300Z"
    }
   },
   "outputs": [],
   "source": [
    "def fuse_rerankers(reranker_type, pre_fusion_weights, post_fusion_weights, topics, rrf_k=60):\n",
    "    \"\"\"\n",
    "    Performs rrf fusion on all the variants of one reranker.\n",
    "    \"\"\"\n",
    "    from processing import Hit\n",
    "    from engine import weighted_rrf_fuse\n",
    "    all_runs = []\n",
    "    for fusion_weight in pre_fusion_weights:\n",
    "        base = load_run(f\"tofuse/run_{reranker_type}_rrf_{fusion_weight}.txt\")\n",
    "        run_hit_format = {}\n",
    "        for qid in base.keys():\n",
    "            run_hit_format[qid]=[Hit(docid=docid, score=0) for docid in base[qid]]\n",
    "        all_runs.append(run_hit_format)\n",
    "\n",
    "    fused = {}\n",
    "    for qid in topics.keys():\n",
    "        fused[qid] = weighted_rrf_fuse([run[qid] for run in all_runs], weights=post_fusion_weights, rrf_k=rrf_k)\n",
    "        with open(f\"Results/fused_fused_rrf_{rrf_k}.txt\", \"a\", encoding=\"utf-8\") as f:\n",
    "            for rank, hit in enumerate(fused[qid], start=1):\n",
    "                f.write(\n",
    "                    f\"{qid} Q0 {hit.docid} {rank} {hit.score:.6f} run42\\n\"\n",
    "                )\n",
    "\n",
    "    run = load_run(f\"Results/fused_fused_rrf_{rrf_k}.txt\")\n",
    "    map_score, ap_by_q = mean_average_precision(qrels, run)\n",
    "    print(f\"MAP for fusion of rerankers of type {reranker_type} with rrf {rrf_k}: {map_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53956a1a50a30c4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T12:35:23.863332Z",
     "start_time": "2026-01-21T12:25:25.033903Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting retrieval with reranker mixedbread-ai/mxbai-rerank-large-v1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Searching topics: 100%|██████████| 50/50 [09:56<00:00, 11.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP for reranker mixedbread-ai/mxbai-rerank-large-v1 with rrf 0: 0.30438937954163175\n",
      "MAP for reranker mixedbread-ai/mxbai-rerank-large-v1 with rrf 0.2: 0.30490620359703724\n",
      "MAP for reranker mixedbread-ai/mxbai-rerank-large-v1 with rrf 0.5: 0.301047600529769\n",
      "MAP for reranker mixedbread-ai/mxbai-rerank-large-v1 with rrf 0.7: 0.2934765819653454\n",
      "MAP for reranker mixedbread-ai/mxbai-rerank-large-v1 with rrf 1: 0.28523687998539804\n"
     ]
    }
   ],
   "source": [
    "# NOTE - fusion_weight = 0 means we take only the reranker, 1 means we take none of the reranker's inputs and it should be identical to pure lexical\n",
    "# For pure lexical only, specify rerankers = [None]\n",
    "# BEST RESULT IS rrf_k = 9\n",
    "#cross-encoder/ms-marco-MiniLM-L-6-v2\" 0.2/0.5\n",
    "# mixedbread-ai/mxbai-rerank-large-v1 0.2\n",
    "# tomaarsen/Qwen3-Reranker-0.6B-seq-cls ??\n",
    "\n",
    "compare_rerankers([topics_subset, topics_expanded_subset, topics_thes], qrels,reranker_type='CE', rerankers= [\"mixedbread-ai/mxbai-rerank-large-v1\"], fusion_weights=[0, 0.2, 0.5, 0.7, 1], query_fusion_weights=[0.8, 0.2, 0.0], rrf_k_queries=9, rrf_k_reranker=60)\n",
    "# for i in range(3,40,2):\n",
    "#     compare_rerankers([topics_subset, topics_expanded_subset, topics_thes], qrels, [None], fusion_weights=[0, 0.2, 0.5, 0.7, 1], rrf_k=i, should_rerank_embedded=True)\n",
    "\n",
    "#\n",
    "# run = load_run(f\"Results/run_CE_rrf_ariel_hits.txt\")\n",
    "# map_score, ap_by_q = mean_average_precision(qrels, run)\n",
    "# print(f\"MAP is: {map_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae38a670aeff00dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fuse_rerankers('CE', [0, 0.2, 0.5, 0.7, 1], [0.0,0.25,0.25,0.25,0.25], topics_subset, rrf_k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0e0e7d41490218",
   "metadata": {},
   "source": [
    "Get LLM datasets and optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91eb0cca37b1e1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from processing import create_llm_generated_queries\n",
    "create_llm_generated_queries(\"Data/LLM_outputs.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db1d76bce4e01ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_llm_weights(queries_paths, qrels, rerankers, fusion_weights):\n",
    "    topics_per_path = [load_topics(path) for path in queries_paths]\n",
    "    shutil.rmtree(\"Results\")\n",
    "    os.makedirs(f\"Results\",exist_ok=True)\n",
    "    for reranker in rerankers:\n",
    "        print(f\"Starting retrieval with reranker {reranker}\")\n",
    "        se = SearchEngine()\n",
    "        se.set_searcher(approach=\"bm25\",fb_terms=20, fb_docs=5, original_query_weight=0.6, mu=300, reranker=\"CE\")\n",
    "        se.search_all_queries(topics, k=1000, m=100, output_file=f\"run_{reranker}\", rerank_fusion_weights=0.2)\n",
    "        for fusion_weight in fusion_weights:\n",
    "            run = load_run(f\"Results/run_{reranker}_rrf_{fusion_weight}.txt\")\n",
    "            map_score, ap_by_q = mean_average_precision(qrels, run)\n",
    "            print(f\"MAP for reranker {reranker} with rrf {fusion_weight}: {map_score}\")\n",
    "            if reranker is None:\n",
    "                break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
